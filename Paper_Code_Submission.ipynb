{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYuA1tUvoXnh"
      },
      "source": [
        "#Section 1 Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX6gPNnVpBKy"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install pytorchtools\n",
        "!pip install efficientnet_pytorch\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1xCsWLVz6ZfO1bddSL1qS5DFAu4B6Ge7p'\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('archive.zip')\n",
        "\n",
        "id = '1u9xj8Quq5oRMU_GLBNTsVaT2B_gNAFRm'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('models.zip')\n",
        "\n",
        "\n",
        "id = '1yE-5rmrWIjG4xiO3Stsj2pAG63NUoQxk'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')\n",
        "\n",
        "\n",
        "!unzip archive.zip\n",
        "!unzip models.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW4I8ApMkeuv"
      },
      "outputs": [],
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "from numpy import arange\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "import random, os\n",
        "from sklearn.metrics import roc_curve\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "import sklearn.utils.class_weight\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch import nn\n",
        "import os\n",
        "import cv2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8VYHYYAQOAV"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "\n",
        "    \n",
        "    random.seed(seed)\n",
        "    \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(5709)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPq4l_U7H1-J"
      },
      "outputs": [],
      "source": [
        "# pre-prcessing data\n",
        "\n",
        "def metadata(ready_train):\n",
        "  ready_train['sex']=ready_train.sex.map({'female': 0, 'male':1})\n",
        "  ready_train['sex'] = ready_train['sex'].replace(np.nan, 2)\n",
        "  age_group = pd.cut(ready_train.age_approx,bins=[0,10,20,30,40,50,60,70,80,100],labels=[1,2,3,4,5,6,7,8,9])\n",
        "  ready_train.insert(4, \"age_group\", age_group)  \n",
        "  ready_train['anatom_site_general_challenge']=ready_train.anatom_site_general_challenge.map({'head/neck': 1, 'upper extremity':2, 'torso':3,'lower extremity':4, 'palms/soles':5 })\n",
        "  ready_train['anatom_site_general_challenge'] = ready_train['anatom_site_general_challenge'].replace(np.nan, 0)\n",
        "  ready_train[\"age_group\"] = ready_train[\"age_group\"].cat.add_categories(0)\n",
        "  ready_train[\"age_group\"].fillna(0, inplace =True)\n",
        "  return ready_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkoOU6TisB0l"
      },
      "outputs": [],
      "source": [
        "full_train = pd.read_csv('train.csv')\n",
        "full_train = metadata(full_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhIcKAt5dU2f"
      },
      "outputs": [],
      "source": [
        "# pre-prcessing data\n",
        "seed_everything(5709)\n",
        "train = pd.read_csv('train.csv')\n",
        "unique_patient_id = train[\"patient_id\"].unique().tolist()\n",
        "len(unique_patient_id)\n",
        "from collections import Counter\n",
        "count= Counter(train[\"patient_id\"])\n",
        "unqualified =[]\n",
        "for i in count:\n",
        "  if count[i]<5:\n",
        "    unqualified.append(i)\n",
        "unqualified_list = train[\"image_name\"][train[\"patient_id\"].isin(unqualified)==True].tolist()\n",
        "train = train[train[\"patient_id\"].isin(unqualified)==False]\n",
        "train = train.reset_index()\n",
        "qualified = train[\"patient_id\"].unique().tolist()\n",
        "\n",
        "     \n",
        "idx =[]\n",
        "for i in qualified:\n",
        "  keep = train[\"index\"][train['patient_id'] == i].tolist()[0:5]\n",
        "  for j in keep:\n",
        "    idx.append(j)\n",
        "clean_train = train[train[\"index\"].isin(idx)==True]\n",
        "remove_train =train[train[\"index\"].isin(idx)==False]\n",
        "remove_list = remove_train[\"image_name\"].tolist()\n",
        "\n",
        "Diagnosed_patient = clean_train[\"patient_id\"][clean_train[\"target\"]== 1].unique().tolist()\n",
        "free_patient = clean_train[\"patient_id\"][clean_train[\"target\"]== 0].unique().tolist()\n",
        "classes= np.array(clean_train[\"target\"].tolist())\n",
        "val_patient_list = random.sample(Diagnosed_patient,int(len(Diagnosed_patient)*0.2))\n",
        "val_patient_list_2 = random.sample(free_patient,int(len(free_patient)*0.2))\n",
        "val_patient_list.extend(val_patient_list_2)\n",
        "random.shuffle (val_patient_list)\n",
        "qualified_val = clean_train[\"patient_id\"][clean_train[\"patient_id\"].isin(val_patient_list)==True].unique().tolist()\n",
        "qualified_train = clean_train[\"patient_id\"][clean_train[\"patient_id\"].isin(val_patient_list)==False].unique().tolist()\n",
        "\n",
        "\n",
        "for_train = full_train[full_train[\"patient_id\"].isin(qualified_val)==False]\n",
        "for_train.to_csv(\"extra_train.csv\", index = False)\n",
        "for_val = full_train[full_train[\"patient_id\"].isin(qualified_val)==True]\n",
        "for_val.to_csv(\"validation.csv\", index = False)\n",
        "train_patient = for_train[\"patient_id\"].unique().tolist()\n",
        "val_patient = for_val[\"patient_id\"].unique().tolist()\n",
        "Full_patient_list = full_train[\"patient_id\"].unique().tolist()\n",
        "classes= np.array(clean_train[\"target\"].tolist())\n",
        "cancer_patient = for_train[\"patient_id\"][for_train[\"target\"]==1].unique().tolist()\n",
        "benign_patient = for_train[\"patient_id\"][for_train[\"patient_id\"].isin(cancer_patient) == False].unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymUr52ThfoUS"
      },
      "outputs": [],
      "source": [
        "# Below codes comes from Roman (2020), URL: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/159476\n",
        "\n",
        "class Microscope:\n",
        "    \"\"\"\n",
        "    Cutting out the edges around the center circle of the image\n",
        "    Imitating a picture, taken through the microscope\n",
        "\n",
        "    Args:\n",
        "        p (float): probability of applying an augmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p: float = 0.5):\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image): Image to apply transformation to.\n",
        "\n",
        "        Returns:\n",
        "            PIL Image: Image with transformation.\n",
        "        \"\"\"\n",
        "        if random.random() < self.p:\n",
        "            circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8), # image placeholder\n",
        "                        (img.shape[0]//2, img.shape[1]//2), # center point of circle\n",
        "                        random.randint(img.shape[0]//2 - 3, img.shape[0]//2 + 15), # radius\n",
        "                        (0, 0, 0), # color\n",
        "                        -1)\n",
        "\n",
        "            mask = circle - 255\n",
        "            img = np.multiply(img, mask)\n",
        "        \n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(p={self.p})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbd__q_bALxk"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "train_dat_tran = transforms.Compose([\n",
        "\n",
        "                                     Microscope(p=0.5),\n",
        "                                     transforms.ToPILImage(),\n",
        "                                     transforms.RandomRotation(45),\n",
        "                                     transforms.RandomResizedCrop(224, scale =(0.8,1.0)),\n",
        "                                     transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.RandomVerticalFlip(),                                    \n",
        "                                     transforms.ColorJitter(brightness=24. / 255.,saturation=0.3),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                          [0.229,0.224,0.225])\n",
        "])                                       \n",
        "val_dat_tran = transforms.Compose([\n",
        "      \n",
        "                                     transforms.ToPILImage(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                          [0.229,0.224,0.225])\n",
        "])    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoSwIk8yAY0B"
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "def onehot(lab, num):\n",
        "  binary =[]\n",
        "  for i in lab:\n",
        "    temp = list(np.zeros(num))\n",
        "    temp[int(i)] =1\n",
        "    binary.append(temp)\n",
        "  return binary\n",
        "def stack(list):\n",
        "  temp = []\n",
        "  for i in list:\n",
        "    for j in i:\n",
        "      temp.append(j)\n",
        "  temp= np.vstack(temp).ravel()\n",
        "\n",
        "  return temp\n",
        "def test(x):\n",
        "  return (1/(1 + np.exp(-x)))\n",
        "\n",
        "  \n",
        "def round (x, prob):\n",
        "  if x>=prob:\n",
        "    x = 1\n",
        "  else:\n",
        "    x = 0\n",
        "\n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx212j9Boj0B"
      },
      "outputs": [],
      "source": [
        "patient_class = []\n",
        "\n",
        "for i in Full_patient_list:\n",
        "  tem = full_train[\"target\"][full_train[\"target\"] == 1][full_train[\"patient_id\"] == i].tolist()\n",
        "  if len(tem) ==0:\n",
        "    patient_class.append(0)\n",
        "  else:\n",
        "    patient_class.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AG5sZHgnoj0B"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "kf = StratifiedKFold(n_splits=5,shuffle=True, random_state=2022)\n",
        "testtt = StratifiedKFold(n_splits=5,shuffle=True, random_state=2022)\n",
        "testtt.get_n_splits(Full_patient_list, patient_class)\n",
        "kf.get_n_splits(Full_patient_list, patient_class)\n",
        "for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "  print(\"TRAIN:\", type(train_index), \"TEST:\", len(test_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFyely1i13U5"
      },
      "outputs": [],
      "source": [
        "time = 0\n",
        "for a,b in kf.split(Full_patient_list, patient_class):\n",
        "  time+=1\n",
        "  print(\"this is time \",time)\n",
        "  for i,j in testtt.split(Full_patient_list, patient_class):\n",
        "      print(np.array_equal(a,i))\n",
        "      print(np.array_equal(b,j))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KCyaFKHu1Iu"
      },
      "outputs": [],
      "source": [
        "# Data loading\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None, target_transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "  \n",
        "      img_path = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0]+\".png\") \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      pat_label = torch.Tensor([self.dataframe.iloc[idx, -1]])\n",
        "\n",
        "\n",
        "      images = cv2.imread(img_path) \n",
        "\n",
        "      if self.transform is not None:\n",
        "          images = self.transform(images)\n",
        "\n",
        "      return images, pat_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMfoSfnTBw4Z"
      },
      "outputs": [],
      "source": [
        "# Below function comes from Brownlee (2020) but with some changes, \n",
        "# URL: https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
        "# finding the best threshold for benign and malignan skin lesion.\n",
        "def threshold(ground_truth,final_prediction):\n",
        "  fpr, tpr, thresholds = roc_curve(ground_truth, final_prediction)\n",
        "  gmeans = np.sqrt(tpr * (1-fpr))\n",
        "  ix = np.argmax(gmeans)\n",
        "  return thresholds[ix], gmeans[ix]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL-XD0W-u82q"
      },
      "outputs": [],
      "source": [
        "# Loading pretrained CNNs\n",
        "CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "num_ftrs = CON._fc.in_features\n",
        "CON._fc = nn.Linear(num_ftrs, 1)\n",
        "CON._fc.require_grad = True\n",
        "\n",
        "RES = models.resnet50(pretrained=True)\n",
        "R_num_ftrs =RES.fc.in_features\n",
        "RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "RES.fc.require_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJnzta6BofH4"
      },
      "source": [
        "#Section 2 Tranining using image feature only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goe8k75OcK0k"
      },
      "source": [
        "##2.1 fine tuning CNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjX_7YywcQLT"
      },
      "outputs": [],
      "source": [
        "# time = 0\n",
        "# for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "#   time +=1\n",
        "#   if time <5:\n",
        "#     continue\n",
        "\n",
        "#   CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "#   num_ftrs = CON._fc.in_features\n",
        "#   CON._fc = nn.Linear(num_ftrs, 1)\n",
        "#   CON._fc.require_grad = True\n",
        "\n",
        "#   RES = models.resnet50(pretrained=True)\n",
        "#   R_num_ftrs =RES.fc.in_features\n",
        "#   RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "#   RES.fc.require_grad = True\n",
        "  \n",
        "#   train_patient = []\n",
        "#   val_patient = []  \n",
        "  \n",
        "#   print(\"this is folder No. \", time)\n",
        "#   tep = []\n",
        "#   for i in test_index:\n",
        "#     tep.append(Full_patient_list[i])\n",
        "#     val_patient.append(Full_patient_list[i])\n",
        "#   for_val = full_train[full_train['patient_id'].isin(tep)==True]\n",
        "#   for_train = full_train[full_train['patient_id'].isin(tep)==False]\n",
        "#   for j in train_index:\n",
        "#     train_patient.append(Full_patient_list[j])\n",
        "#   ones = len(for_train[for_train['target']==1])\n",
        "#   zeros = len(for_train)-ones\n",
        "#   a = np.zeros(zeros)\n",
        "#   b = np.ones(ones)\n",
        "#   c = np.concatenate((a,b))\n",
        "#   random.shuffle(c)\n",
        "\n",
        "#   class_weights=sklearn.utils.class_weight.compute_class_weight('balanced',classes = np.unique(c),y=c)\n",
        "#   class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "#   class_weights = class_weights[1]/class_weights[0]\n",
        "\n",
        "#   batch_size = 30\n",
        "#   train_data_cleaned = CustomImageDataset(for_train, '/content/train/', train_dat_tran)\n",
        "#   val_data_cleaned = CustomImageDataset(for_val, '/content/train/', val_dat_tran)\n",
        "#   dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "#   dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "#   # Fine-tune efficientNet CNNs\n",
        "#   print('Fine-tune efficientNet CNNs')\n",
        "#   print(\"this is folder No. \", time)\n",
        "#   learning_rate = 0.001\n",
        "#   epochs = 10\n",
        "#   model = CON\n",
        "#   model = model.to(device)\n",
        "\n",
        "#   train_roc_auc = []\n",
        "\n",
        "#   train_loss = []\n",
        "\n",
        "#   val_roc_auc = []\n",
        "\n",
        "#   val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "#   criterion = nn.BCEWithLogitsLoss()\n",
        "#   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#           optimizer,\n",
        "#           patience=1,\n",
        "#           factor=0.2,\n",
        "#           threshold=0.001,\n",
        "#           mode=\"max\",\n",
        "#           verbose=True\n",
        "#       )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   for epoch in range(epochs):\n",
        "#       train_pred = []\n",
        "#       train_truth=[]\n",
        "      \n",
        "#       final_prediction= []\n",
        "#       ground_truth = []\n",
        "#       print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "#       epoch_loss=0.0    \n",
        "#       epoch_acc =0.0\n",
        "      \n",
        "#       #train the model\n",
        "#       model.train()\n",
        "      \n",
        "#       batch_iteration = 0\n",
        "#       for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "#         image_in, label_in = data\n",
        "#         optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "#         label_in= label_in.to(device)\n",
        "\n",
        "#         image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "#         train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "#         label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "#         loss = criterion(train_output, label_in)\n",
        "        \n",
        "#         prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "#         loss.backward()\n",
        "\n",
        "#         optimizer.step()\n",
        "        \n",
        "        \n",
        "#         batchloss = loss.item()\n",
        "#         t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "#         train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "#         train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "#         epoch_loss += batchloss\n",
        "#         epoch_acc += t_acc\n",
        "#         count = i\n",
        "        \n",
        "#         if i % 100 == 99:\n",
        "\n",
        "#           print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "#       train_pred = stack(train_pred)\n",
        "#       train_truth = stack(train_truth)\n",
        "#       print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "#       print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "#       train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "#       train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "#       model.eval()\n",
        "      \n",
        "#       val_epoch_loss = 0.0\n",
        "#       val_epoch_acc = 0.0  \n",
        "#       with torch.no_grad():\n",
        "#         for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "#           v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "#           v_label_in= v_label_in.to(device)\n",
        "\n",
        "#           v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "#           val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "#           loss = criterion(val_output, v_label_in)\n",
        "\n",
        "#           v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "#           batchloss = loss.item()\n",
        "\n",
        "\n",
        "#           final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "#           ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "#           if j % 10 == 9:\n",
        "\n",
        "\n",
        "#             print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "#           val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "#         final_prediction = stack(final_prediction)\n",
        "\n",
        "#         ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "#         print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "#         print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "#         scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "#         val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "#         val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "#   torch.save(model, \"/content/model/EfficientNetB4_folderNo._{}.pt\".format(time))\n",
        "#   torch.cuda.empty_cache()\n",
        "\n",
        "#   # Fine-tune ResNet CNNs\n",
        "#   print('Fine-tune ResNet CNNs')\n",
        "#   print(\"this is folder No. \", time)\n",
        "#   learning_rate = 0.001\n",
        "#   epochs = 10\n",
        "#   model = RES\n",
        "#   model = model.to(device)\n",
        "\n",
        "#   train_roc_auc = []\n",
        "\n",
        "#   train_loss = []\n",
        "\n",
        "#   val_roc_auc = []\n",
        "\n",
        "#   val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "#   criterion = nn.BCEWithLogitsLoss()\n",
        "#   scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#           optimizer,\n",
        "#           patience=1,\n",
        "#           factor=0.2,\n",
        "#           threshold=0.001,\n",
        "#           mode=\"max\",\n",
        "#           verbose=True\n",
        "#       )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   for epoch in range(epochs):\n",
        "#       train_pred = []\n",
        "#       train_truth=[]\n",
        "      \n",
        "#       final_prediction= []\n",
        "#       ground_truth = []\n",
        "#       print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "#       epoch_loss=0.0    \n",
        "#       epoch_acc =0.0\n",
        "      \n",
        "#       #train the model\n",
        "#       model.train()\n",
        "      \n",
        "#       batch_iteration = 0\n",
        "#       for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "#         image_in, label_in = data\n",
        "#         optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "#         label_in= label_in.to(device)\n",
        "\n",
        "#         image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "#         train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "#         label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "#         loss = criterion(train_output, label_in)\n",
        "        \n",
        "#         prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "#         loss.backward()\n",
        "\n",
        "#         optimizer.step()\n",
        "        \n",
        "        \n",
        "#         batchloss = loss.item()\n",
        "#         t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "#         train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "#         train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "#         epoch_loss += batchloss\n",
        "#         epoch_acc += t_acc\n",
        "#         count = i\n",
        "        \n",
        "#         if i % 100 == 99:\n",
        "\n",
        "#           print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "#       train_pred = stack(train_pred)\n",
        "#       train_truth = stack(train_truth)\n",
        "#       print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "#       print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "#       train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "#       train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "#       model.eval()\n",
        "      \n",
        "#       val_epoch_loss = 0.0\n",
        "#       val_epoch_acc = 0.0  \n",
        "#       with torch.no_grad():\n",
        "#         for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "#           v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "#           v_label_in= v_label_in.to(device)\n",
        "\n",
        "#           v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "#           val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "#           loss = criterion(val_output, v_label_in)\n",
        "\n",
        "#           v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "#           batchloss = loss.item()\n",
        "\n",
        "\n",
        "#           final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "#           ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "#           if j % 10 == 9:\n",
        "\n",
        "\n",
        "#             print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "#           val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "#         final_prediction = stack(final_prediction)\n",
        "\n",
        "#         ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "#         print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "#         print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "#         scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "#         val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "#         val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "\n",
        "#   torch.save(model, \"/content/model/ResNet50_folderNo._{}.pt\".format(time))\n",
        "\n",
        "# print(\"pretrained CNN tuning complete\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe0St8p1-HBm"
      },
      "outputs": [],
      "source": [
        "# id = '1yE-5rmrWIjG4xiO3Stsj2pAG63NUoQxk'\n",
        "# downloaded = drive.CreateFile({'id':id}) \n",
        "# downloaded.GetContentFile('train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfhYClC5rOg6"
      },
      "source": [
        "##2.2 Training using EfficientB4 + MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N41bcuAJoxKN"
      },
      "outputs": [],
      "source": [
        "#MLP:\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "                \n",
        "                nn.Linear(1793*pic,1024),\n",
        "                #nn.LayerNorm([1,1024]),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(1024,512),\n",
        "                #nn.LayerNorm([1,512]),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(512,256),\n",
        "                #nn.LayerNorm([1,256]),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(256,1)\n",
        "                \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "              \n",
        "        z = self.predictor(x)\n",
        "        z = torch.flatten(z)\n",
        "        z = z.view(-1,1)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkvO_SWpqqqr"
      },
      "outputs": [],
      "source": [
        "# Making prediction and extracting image features\n",
        "\n",
        "class Final_model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Final_model, self).__init__()\n",
        "    self.CNN = CON\n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, image):\n",
        "    feature_record=[]\n",
        "    feature_record2=[]\n",
        "\n",
        "\n",
        "    for img in image:\n",
        "      \n",
        "      img = img.to(device)\n",
        "\n",
        " \n",
        "      feature = self.CNN(img)\n",
        "      feature2= self.CNN.extract_features(img)\n",
        "      feature2 = self.CNN._avg_pooling(feature2)\n",
        "\n",
        "\n",
        "      feature2 = torch.flatten(feature2,1)\n",
        "\n",
        "      feature = self.sig(feature)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "      feature_shape = feature.shape[1]\n",
        "\n",
        "      feature_shape2 = feature2.shape[1]\n",
        "\n",
        "\n",
        " \n",
        "      feature_record.append(feature)\n",
        "      feature_record2.append(feature2)\n",
        "   \n",
        "\n",
        "    feature_record= torch.stack(feature_record).reshape(-1,pic,feature_shape)\n",
        "    feature_record2= torch.stack(feature_record2).reshape(-1,pic,feature_shape2)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    return feature_record,feature_record2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sU27aXvxf-1"
      },
      "outputs": [],
      "source": [
        "# Define data loading for patient-level classification\n",
        "\n",
        "class CustomImageDataset3(Dataset):\n",
        "    def __init__(self, patient_list, img_dir, transform=None, target_transform=None):\n",
        "        self.patient_list = patient_list\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      total = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]].tolist()\n",
        "      malignant = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]][full_train[\"target\"] == 1].tolist()\n",
        "      temp = full_train[\"image_name\"][full_train[\"image_name\"].isin(malignant) == False][full_train[\"patient_id\"]== self.patient_list[idx]].tolist()\n",
        "      img_list =[]\n",
        "      if len(malignant) >= pic:\n",
        "        \n",
        "        img_list.extend(malignant[0:pic])\n",
        "      else:\n",
        "        if len(temp)>= pic-len(malignant):\n",
        "          img_list.extend(malignant)\n",
        "          \n",
        "          img_list.extend(temp[0:pic-len(malignant)])\n",
        "        else:\n",
        "          img_list.extend(temp)\n",
        "          for i in range(pic-len(malignant)-len(temp)):\n",
        "            img_list.extend([total[0]])\n",
        "\n",
        "\n",
        "      if len(img_list)!=pic:\n",
        "        for i in range(pic-len(img_list)):\n",
        "          img_list.extend([total[0]])\n",
        "\n",
        "     \n",
        "      img_labels = [full_train[\"target\"][full_train[\"image_name\"]== a].values[0] for a in img_list]\n",
        "      img_labels = torch.Tensor(img_labels)\n",
        "\n",
        "      if len(malignant)>0:\n",
        "        pat_label = torch.tensor([1], dtype= torch.float32) \n",
        "      else:\n",
        "        pat_label = torch.tensor([0], dtype= torch.float32)\n",
        "\n",
        "      img_paths = [os.path.join(self.img_dir, i +\".png\") for i in img_list]\n",
        "      images = [cv2.imread(img_path) for img_path in img_paths]\n",
        "\n",
        "      if self.transform is not None:\n",
        "          images = [self.transform(image) for image in images]\n",
        "\n",
        "      \n",
        "      # print(len(images))\n",
        "      # print(img_labels.shape)\n",
        "      \n",
        "      \n",
        "\n",
        "      return images, pat_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4UpIXH1puhx"
      },
      "outputs": [],
      "source": [
        "time = 0\n",
        "for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "  time +=1\n",
        "  # if time <5:\n",
        "  #   continue\n",
        "\n",
        "  # CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "  # num_ftrs = CON._fc.in_features\n",
        "  # CON._fc = nn.Linear(num_ftrs, 1)\n",
        "  # CON._fc.require_grad = True\n",
        "\n",
        "  # RES = models.resnet50(pretrained=True)\n",
        "  # R_num_ftrs =RES.fc.in_features\n",
        "  # RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "  # RES.fc.require_grad = True\n",
        "  \n",
        "  train_patient = []\n",
        "  val_patient = []  \n",
        "  \n",
        "  print(\"this is folder No. \", time)\n",
        "  tep = []\n",
        "  for i in test_index:\n",
        "    tep.append(Full_patient_list[i])\n",
        "    val_patient.append(Full_patient_list[i])\n",
        "  for_val = full_train[full_train['patient_id'].isin(tep)==True]\n",
        "  for_train = full_train[full_train['patient_id'].isin(tep)==False]\n",
        "  for j in train_index:\n",
        "    train_patient.append(Full_patient_list[j])\n",
        "  ones = len(for_train[for_train['target']==1])\n",
        "  zeros = len(for_train)-ones\n",
        "  a = np.zeros(zeros)\n",
        "  b = np.ones(ones)\n",
        "  c = np.concatenate((a,b))\n",
        "  random.shuffle(c)\n",
        "\n",
        "  class_weights=sklearn.utils.class_weight.compute_class_weight('balanced',classes = np.unique(c),y=c)\n",
        "  class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "  class_weights = class_weights[1]/class_weights[0]\n",
        "\n",
        "  batch_size = 30\n",
        "  train_data_cleaned = CustomImageDataset(for_train, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset(for_val, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "  # # Fine-tune efficientNet CNNs\n",
        "  # print('Fine-tune efficientNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = CON\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  # torch.save(model, 'EfficientNetB4_pretrained_final.pt')\n",
        "  # torch.cuda.empty_cache()\n",
        "\n",
        "  # # Fine-tune ResNet CNNs\n",
        "  # print('Fine-tune ResNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = RES\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "\n",
        "  # torch.save(model, 'ResNet50_pretrained_Final.pt')\n",
        "\n",
        "  CON = torch.load(\"/content/model/EfficientNetB4_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  RESNET = torch.load(\"/content/model/ResNet50_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  ## EfficientNetB4\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = CON\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer.zero_grad()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  thres, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  ## ResNet50\n",
        "  print('getting ResNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = RESNET\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "  \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "                         \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val)))\n",
        "\n",
        "  thres2, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  #EfficientNet B4 and MLP\n",
        "  print('train the model EfficientNet B4 and MLP')\n",
        "  print(\"this is folder No. \", time)\n",
        "  pic = 20\n",
        "  batch_size = 1\n",
        "  n_class = 1\n",
        "  batch_size = 1\n",
        "  n_input = 1793\n",
        "  n_hidden = 2048\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  train_data_cleaned = CustomImageDataset3(train_patient, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset3(val_patient, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "\n",
        "  # EfficientNetB4 + MLP \n",
        "\n",
        "  learning_rate = 0.0001\n",
        "  epochs = 1\n",
        "  model1 = Final_model().to(device)\n",
        "\n",
        "  model = MLP().to(device)\n",
        "\n",
        "  model1.eval()\n",
        "\n",
        "\n",
        "  train_roc_auc =[]\n",
        "\n",
        "  train_loss=[]\n",
        "\n",
        "  val_roc_auc=[]\n",
        "\n",
        "  val_loss=[]\n",
        "\n",
        "\n",
        "  val_f1 = []\n",
        "\n",
        "  train_f1 = []\n",
        "\n",
        "\n",
        "\n",
        "  class_weights = class_weights.to(device)\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "  criterion = nn.BCEWithLogitsLoss(pos_weight = class_weights)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=2,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "      print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "      epoch_loss=0.0    \n",
        "      epoch_acc =0.0\n",
        "      \n",
        "      #train the model\n",
        "      model.train()\n",
        "      \n",
        "      batch_iteration = 0\n",
        "      for i, data in enumerate(dataloadingfortrain, 0):\n",
        "        try:\n",
        "\n",
        "          image_in, label_in = data\n",
        "          optimizer.zero_grad()\n",
        "    \n",
        "          \n",
        "          label_in= label_in.to(device)\n",
        "\n",
        "          \n",
        "          train_output,train_output2 = model1(image_in)\n",
        "          train_output[train_output<thres] =torch.tensor([0], dtype= torch.float32).to(device)\n",
        "\n",
        "          train_output[train_output>=thres] =torch.tensor([1], dtype= torch.float32).to(device)\n",
        "\n",
        "\n",
        "          train_output = torch.cat((train_output2,train_output), dim =-1)\n",
        "\n",
        "          train_output =train_output.view(1,-1)\n",
        "          train_output = model(train_output)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "          label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "            \n",
        "          loss = criterion(train_output, label_in)\n",
        "          \n",
        "          prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "          \n",
        "          t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=True)\n",
        "          train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "          train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "          epoch_loss += batchloss\n",
        "          epoch_acc += t_acc\n",
        "          count = i\n",
        "          \n",
        "          if i % 500 == 499:\n",
        "\n",
        "            print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "        except ValueError: \n",
        "\n",
        "          print(prediction.detach().cpu().numpy())      \n",
        "\n",
        "          print(np.round(prediction.detach().cpu().numpy()))           \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      train_pred = stack(train_pred)\n",
        "      train_truth = stack(train_truth)\n",
        "      print(\"epoch average auc: \", roc_auc_score(train_truth, train_pred))\n",
        "      print(\"epoch average loss: \", epoch_loss/(len(train_patient)))\n",
        "      train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "      train_loss.append(epoch_loss/(len(train_patient)))\n",
        "      \n",
        "      \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "\n",
        "          \n",
        "      \n",
        "          \n",
        "        \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "\n",
        "          val_output,val_output2 = model1(v_image_in)\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "          val_output[val_output<thres] =0.0\n",
        "          val_output[val_output>=thres] =1.0\n",
        "      \n",
        "          val_output = torch.cat((val_output2,val_output), dim =-1)\n",
        "\n",
        "          \n",
        "          val_output =val_output.view(1,-1)\n",
        "          val_output = model(val_output)\n",
        "\n",
        "    \n",
        "        \n",
        "      \n",
        "          v_label_in=v_label_in.view(-1, 1).type_as(val_output)\n",
        "                \n",
        "          \n",
        "          \n",
        "      \n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "      \n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "        scheduler.step(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  temp_list = pd.DataFrame({'train_roc_auc' : train_roc_auc,\n",
        "                                  'train_loss' : train_loss,\n",
        "                                  'val_roc_auc' : val_roc_auc,\n",
        "                                  'val_loss' : val_loss,\n",
        "                                  }, \n",
        "                                  columns=['train_roc_auc','train_loss', 'val_roc_auc','val_loss' ])\n",
        "\n",
        "  temp_list.to_csv(\"/content/EfficientNetB4_and_MLP_folderNo._{}.csv\".format(time), index = False)\n",
        "print(\"cycle complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yootLMjrUYm"
      },
      "source": [
        "##2.3 Training with model: EfficientNetB4 + Bidirectional RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxmAM6bTrY9Q"
      },
      "outputs": [],
      "source": [
        "#RNN\n",
        "\n",
        "class Bi_RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_RNN, self).__init__()\n",
        " \n",
        "        self.RNN = nn.RNN(n_input,n_hidden, num_layers = 2, batch_first =True, bidirectional=True)\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "                \n",
        "                nn.Linear(n_hidden*2,1024),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(1024,512),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(512,256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(256,n_class)\n",
        "                \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "              \n",
        "        RNN_out, h_n = self.RNN(x)\n",
        "\n",
        "        hidden_out =torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.predictor(hidden_out)\n",
        "        z = torch.flatten(z)\n",
        "        z = z.view(-1,1)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSI2qZ2-Cwzj"
      },
      "outputs": [],
      "source": [
        "# Making prediction and extracting image features\n",
        "\n",
        "class Final_model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Final_model, self).__init__()\n",
        "    self.CNN = CON\n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, image):\n",
        "    feature_record=[]\n",
        "    feature_record2=[]\n",
        "\n",
        "\n",
        "    for img in image:\n",
        "      \n",
        "      img = img.to(device)\n",
        "\n",
        " \n",
        "      feature = self.CNN(img)\n",
        "      feature2= self.CNN.extract_features(img)\n",
        "      feature2 = self.CNN._avg_pooling(feature2)\n",
        "\n",
        "      feature2 = torch.flatten(feature2,1)\n",
        "\n",
        "      feature = self.sig(feature)\n",
        "\n",
        "    \n",
        "      feature_shape = feature.shape[1]\n",
        "\n",
        "      feature_shape2 = feature2.shape[1]\n",
        "\n",
        "\n",
        " \n",
        "      feature_record.append(feature)\n",
        "      feature_record2.append(feature2)\n",
        "   \n",
        "\n",
        "    feature_record= torch.stack(feature_record).reshape(-1,pic,feature_shape)\n",
        "    feature_record2= torch.stack(feature_record2).reshape(-1,pic,feature_shape2)\n",
        "\n",
        "   \n",
        "    return feature_record,feature_record2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKhK3FQJK2Ey"
      },
      "outputs": [],
      "source": [
        "# Define data loading for patient-level classification\n",
        "\n",
        "class CustomImageDataset3(Dataset):\n",
        "    def __init__(self, patient_list, img_dir, transform=None, target_transform=None):\n",
        "        self.patient_list = patient_list\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      total = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]].tolist()\n",
        "      malignant = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]][full_train[\"target\"] == 1].tolist()\n",
        "      temp = full_train[\"image_name\"][full_train[\"image_name\"].isin(malignant) == False][full_train[\"patient_id\"]== self.patient_list[idx]].tolist()\n",
        "      img_list =[]\n",
        "      if len(malignant) >= pic:\n",
        "        \n",
        "        img_list.extend(malignant[0:pic])\n",
        "      else:\n",
        "        if len(temp)>= pic-len(malignant):\n",
        "          img_list.extend(malignant)\n",
        "          \n",
        "          img_list.extend(temp[0:pic-len(malignant)])\n",
        "        else:\n",
        "          img_list.extend(temp)\n",
        "          for i in range(pic-len(malignant)-len(temp)):\n",
        "            img_list.extend([total[0]])\n",
        "\n",
        "\n",
        "      if len(img_list)!=pic:\n",
        "        for i in range(pic-len(img_list)):\n",
        "          img_list.extend([total[0]])\n",
        "\n",
        "     \n",
        "      img_labels = [full_train[\"target\"][full_train[\"image_name\"]== a].values[0] for a in img_list]\n",
        "      img_labels = torch.Tensor(img_labels)\n",
        "\n",
        "      if len(malignant)>0:\n",
        "        pat_label = torch.tensor([1], dtype= torch.float32) \n",
        "      else:\n",
        "        pat_label = torch.tensor([0], dtype= torch.float32)\n",
        "\n",
        "      img_paths = [os.path.join(self.img_dir, i +\".png\") for i in img_list]\n",
        "      images = [cv2.imread(img_path) for img_path in img_paths]\n",
        "\n",
        "      if self.transform is not None:\n",
        "          images = [self.transform(image) for image in images]\n",
        "\n",
        "      \n",
        "      # print(len(images))\n",
        "      # print(img_labels.shape)\n",
        "      \n",
        "      \n",
        "\n",
        "      return images, pat_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5JfjKhkrbYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a177667-e45a-4dcf-8bd0-7e6e014b3037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is folder No.  1\n",
            "getting EfficientNet threshold\n",
            "this is folder No.  1\n",
            "this is  100 th patch\n",
            "this is  200 th patch\n",
            "this is  300 th patch\n",
            "this is  400 th patch\n",
            "this is  500 th patch\n",
            "this is  600 th patch\n",
            "this is  700 th patch\n",
            "this is  800 th patch\n",
            "epoch average loss for validation:  0.0090157428786986\n",
            "validation roc_auc_score 0.9041654789242499\n",
            "getting EfficientNet threshold\n",
            "this is folder No.  1\n",
            "this is  100 th patch\n",
            "this is  200 th patch\n",
            "this is  300 th patch\n",
            "this is  400 th patch\n",
            "this is  500 th patch\n",
            "this is  600 th patch\n",
            "this is  700 th patch\n",
            "this is  800 th patch\n",
            "epoch average loss for validation:  0.011058334548536523\n",
            "validation roc_auc_score 0.792006952320247\n",
            "Training model EfficientNetB4 + Bi-directional RNN  5 images per patient\n",
            "this is folder No.  1\n",
            "this is epoch  1 running\n",
            "epoch  1   500 th batch accuracy:  0.0 loss:  4.111856460571289\n"
          ]
        }
      ],
      "source": [
        "time = 0\n",
        "for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "  time +=1  \n",
        "  # if time < 5:\n",
        "  #   continue\n",
        "  # CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "  # num_ftrs = CON._fc.in_features\n",
        "  # CON._fc = nn.Linear(num_ftrs, 1)\n",
        "  # CON._fc.require_grad = True\n",
        "\n",
        "  # RES = models.resnet50(pretrained=True)\n",
        "  # R_num_ftrs =RES.fc.in_features\n",
        "  # RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "  # RES.fc.require_grad = True\n",
        "\n",
        "  train_patient = []\n",
        "  val_patient = []  \n",
        "  \n",
        "  print(\"this is folder No. \", time)\n",
        "  tep = []\n",
        "  for i in test_index:\n",
        "    tep.append(Full_patient_list[i])\n",
        "    val_patient.append(Full_patient_list[i])\n",
        "  for_val = full_train[full_train['patient_id'].isin(tep)==True]\n",
        "  for_train = full_train[full_train['patient_id'].isin(tep)==False]\n",
        "  for j in train_index:\n",
        "    train_patient.append(Full_patient_list[j])\n",
        "  ones = len(for_train[for_train['target']==1])\n",
        "  zeros = len(for_train)-ones\n",
        "  a = np.zeros(zeros)\n",
        "  b = np.ones(ones)\n",
        "  c = np.concatenate((a,b))\n",
        "  random.shuffle(c)\n",
        "\n",
        "  class_weights=sklearn.utils.class_weight.compute_class_weight('balanced',classes = np.unique(c),y=c)\n",
        "  class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "  class_weights = class_weights[1]/class_weights[0]\n",
        "\n",
        "  batch_size = 30\n",
        "  train_data_cleaned = CustomImageDataset(for_train, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset(for_val, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "  # # Fine-tune efficientNet CNNs\n",
        "  # print('Fine-tune efficientNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = CON\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  # torch.save(model, 'EfficientNetB4_pretrained_final.pt')\n",
        "\n",
        "  # # Fine-tune ResNet CNNs\n",
        "  # print('Fine-tune ResNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = RES\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "\n",
        "  # torch.save(model, 'ResNet50_pretrained_Final.pt')\n",
        "\n",
        "  # CON = torch.load('EfficientNetB4_pretrained_final.pt')\n",
        "\n",
        "  # RESNET = torch.load('ResNet50_pretrained_Final.pt')\n",
        "\n",
        "  CON = torch.load(\"/content/model/EfficientNetB4_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  RESNET = torch.load(\"/content/model/ResNet50_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  ## EfficientNetB4\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = CON\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  thres, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  \n",
        "  ## ResNet50\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = RESNET\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "  \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "                         \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val)))\n",
        "\n",
        "  thres2, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  pic = 20\n",
        "  batch_size = 1\n",
        "  n_class = 1\n",
        "  batch_size = 1\n",
        "  n_input = 1793\n",
        "  n_hidden = 2048\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  train_data_cleaned = CustomImageDataset3(train_patient, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset3(val_patient, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "  print(\"Training model EfficientNetB4 + Bi-directional RNN  5 images per patient\")\n",
        "  print(\"this is folder No. \", time)\n",
        "  # EfficientNetB4 + Bi-directional RNN  5 images per patient\n",
        "\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model1 = Final_model().to(device)\n",
        "  # model2 = Final_model1().to(device)\n",
        "  model = Bi_RNN().to(device)\n",
        "\n",
        "  model1.eval()\n",
        "\n",
        "  # model2.eval()\n",
        "  train_roc_auc =[]\n",
        "\n",
        "  train_loss=[]\n",
        "\n",
        "  val_roc_auc=[]\n",
        "\n",
        "  val_loss=[]\n",
        "\n",
        "\n",
        "  val_f1 = []\n",
        "\n",
        "  train_f1 = []\n",
        "\n",
        "\n",
        "  # pos_weight = class_weights\n",
        "  class_weights = class_weights.to(device)\n",
        "  # weight=class_weights,reduction='mean'\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss(weight=class_weights,reduction='mean')\n",
        "  criterion = nn.BCEWithLogitsLoss(pos_weight = class_weights)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=2,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "      print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "      epoch_loss=0.0    \n",
        "      epoch_acc =0.0\n",
        "      \n",
        "      #train the model\n",
        "      model.train()\n",
        "      \n",
        "      batch_iteration = 0\n",
        "      for i, data in enumerate(dataloadingfortrain, 0):\n",
        "        try:\n",
        "\n",
        "          image_in, label_in = data\n",
        "          optimizer.zero_grad()\n",
        "    \n",
        "          \n",
        "          label_in= label_in.to(device)\n",
        "\n",
        "          \n",
        "          train_output,train_output2 = model1(image_in)\n",
        "          train_output[train_output<thres] =torch.tensor([0], dtype= torch.float32).to(device)\n",
        "\n",
        "          train_output[train_output>=thres] =torch.tensor([1], dtype= torch.float32).to(device)\n",
        "\n",
        "          train_output = torch.cat((train_output2,train_output), dim =-1)\n",
        "\n",
        "          train_output = model(train_output)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "          label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "            \n",
        "          loss = criterion(train_output, label_in)\n",
        "          \n",
        "          prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "          \n",
        "          t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=True)\n",
        "          train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "          train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "          epoch_loss += batchloss\n",
        "          epoch_acc += t_acc\n",
        "          count = i\n",
        "          \n",
        "          if i % 500 == 499:\n",
        "\n",
        "            print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "        except ValueError: \n",
        "\n",
        "          print(prediction.detach().cpu().numpy())      \n",
        "\n",
        "          print(np.round(prediction.detach().cpu().numpy()))           \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      train_pred = stack(train_pred)\n",
        "      train_truth = stack(train_truth)\n",
        "      print(\"epoch average auc: \", roc_auc_score(train_truth, train_pred))\n",
        "      print(\"epoch average loss: \", epoch_loss/(len(train_patient)))\n",
        "      train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "      train_loss.append(epoch_loss/(len(train_patient)))\n",
        "      \n",
        "      \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "\n",
        "          \n",
        "          \n",
        "        \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "\n",
        "          val_output,val_output2 = model1(v_image_in)\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "          val_output[val_output<thres] =0.0\n",
        "          val_output[val_output>=thres] =1.0\n",
        "\n",
        "          val_output = torch.cat((val_output2,val_output), dim =-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          val_output = model(val_output)\n",
        "\n",
        "    \n",
        "        \n",
        "      \n",
        "          v_label_in=v_label_in.view(-1, 1).type_as(val_output)\n",
        "                \n",
        "      \n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "        \n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "        print(\"roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "        scheduler.step(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  temp_list = pd.DataFrame({'train_roc_auc' : train_roc_auc,\n",
        "                                  'train_loss' : train_loss,\n",
        "                                  'val_roc_auc' : val_roc_auc,\n",
        "                                  'val_loss' : val_loss,\n",
        "                                  }, \n",
        "                                  columns=['train_roc_auc','train_loss', 'val_roc_auc','val_loss' ])\n",
        "\n",
        "  temp_list.to_csv(\"/content/EfficientNetB4_and_BIRNN_folderNo._{}.csv\".format(time), index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lqnMATCr6hG"
      },
      "source": [
        "##2.4 Training with model: EfficientNetB4 + Bi-directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FegG1MNLMvB5"
      },
      "outputs": [],
      "source": [
        "# LSTM \n",
        "\n",
        "class Bi_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM, self).__init__()\n",
        " \n",
        "        self.lstm = nn.LSTM(n_input,n_hidden, num_layers = 2, batch_first =True, bidirectional=True)\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "                \n",
        "                nn.Linear(n_hidden*2,1024),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(1024,512),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(512,256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(256,n_class)\n",
        "                \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "              \n",
        "        lstm_out, (h_n,c_n) = self.lstm(x)\n",
        "\n",
        "        hidden_out =torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.predictor(hidden_out)\n",
        "        z = torch.flatten(z)\n",
        "        z = z.view(-1,1)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VraMdrJxf-0"
      },
      "outputs": [],
      "source": [
        "class Final_model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Final_model, self).__init__()\n",
        "    self.CNN = CON\n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, image):\n",
        "    feature_record=[]\n",
        "    feature_record2=[]\n",
        "\n",
        "\n",
        "    for img in image:\n",
        "      \n",
        "      img = img.to(device)\n",
        "\n",
        " \n",
        "      feature = self.CNN(img)\n",
        "      feature2= self.CNN.extract_features(img)\n",
        "      feature2 = self.CNN._avg_pooling(feature2)\n",
        "\n",
        "\n",
        "      feature2 = torch.flatten(feature2,1)\n",
        "\n",
        "      feature = self.sig(feature)\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      feature_shape = feature.shape[1]\n",
        "\n",
        "      feature_shape2 = feature2.shape[1]\n",
        "\n",
        " \n",
        "      feature_record.append(feature)\n",
        "      feature_record2.append(feature2)\n",
        "\n",
        "\n",
        "    feature_record= torch.stack(feature_record).reshape(-1,pic,feature_shape)\n",
        "    feature_record2= torch.stack(feature_record2).reshape(-1,pic,feature_shape2)\n",
        "\n",
        "    \n",
        "    \n",
        "    return feature_record,feature_record2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtMcklmfr-EA"
      },
      "outputs": [],
      "source": [
        "time = 0\n",
        "for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "  time +=1\n",
        "  # if time <5:\n",
        "  #   continue\n",
        "  # CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "  # num_ftrs = CON._fc.in_features\n",
        "  # CON._fc = nn.Linear(num_ftrs, 1)\n",
        "  # CON._fc.require_grad = True\n",
        "\n",
        "  # RES = models.resnet50(pretrained=True)\n",
        "  # R_num_ftrs =RES.fc.in_features\n",
        "  # RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "  # RES.fc.require_grad = True\n",
        "\n",
        "  train_patient = []\n",
        "  val_patient = []  \n",
        "  \n",
        "  print(\"this is folder No. \", time)\n",
        "  tep = []\n",
        "  for i in test_index:\n",
        "    tep.append(Full_patient_list[i])\n",
        "    val_patient.append(Full_patient_list[i])\n",
        "  for_val = full_train[full_train['patient_id'].isin(tep)==True]\n",
        "  for_train = full_train[full_train['patient_id'].isin(tep)==False]\n",
        "  for j in train_index:\n",
        "    train_patient.append(Full_patient_list[j])\n",
        "  ones = len(for_train[for_train['target']==1])\n",
        "  zeros = len(for_train)-ones\n",
        "  a = np.zeros(zeros)\n",
        "  b = np.ones(ones)\n",
        "  c = np.concatenate((a,b))\n",
        "  random.shuffle(c)\n",
        "\n",
        "  class_weights=sklearn.utils.class_weight.compute_class_weight('balanced',classes = np.unique(c),y=c)\n",
        "  class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "  class_weights = class_weights[1]/class_weights[0]\n",
        "\n",
        "  batch_size = 30\n",
        "  train_data_cleaned = CustomImageDataset(for_train, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset(for_val, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "  # # Fine-tune efficientNet CNNs\n",
        "  # print('Fine-tune efficientNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = CON\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  # torch.save(model, 'EfficientNetB4_pretrained_final.pt')\n",
        "\n",
        "  # # Fine-tune ResNet CNNs\n",
        "  # print('Fine-tune ResNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = RES\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "\n",
        "  # torch.save(model, 'ResNet50_pretrained_Final.pt')\n",
        "\n",
        "  CON = torch.load(\"/content/model/EfficientNetB4_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  RESNET = torch.load(\"/content/model/ResNet50_folderNo._{}.pt\".format(time))\n",
        "\n",
        "\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  ## EfficientNetB4\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = CON\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  thres, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  \n",
        "  ## ResNet50\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = RESNET\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "  \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "                         \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val)))\n",
        "\n",
        "  thres2, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  pic = 15\n",
        "  batch_size = 1\n",
        "  n_class = 1\n",
        "  batch_size = 1\n",
        "  n_input = 1793\n",
        "  n_hidden = 2048\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  train_data_cleaned = CustomImageDataset3(train_patient, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset3(val_patient, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "  # EfficientNetB4 + Bi-directional LSTM\n",
        "  print(\"Training model EfficientNetB4 + Bi-directional LSTM 5 PIC\")\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model1 = Final_model().to(device)\n",
        "\n",
        "  model = Bi_LSTM().to(device)\n",
        "\n",
        "  model1.eval()\n",
        "\n",
        "\n",
        "  train_roc_auc =[]\n",
        "\n",
        "  train_loss=[]\n",
        "\n",
        "  val_roc_auc=[]\n",
        "\n",
        "  val_loss=[]\n",
        "\n",
        "\n",
        "  val_f1 = []\n",
        "\n",
        "  train_f1 = []\n",
        "\n",
        "\n",
        "\n",
        "  class_weights = class_weights.to(device)\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "  criterion = nn.BCEWithLogitsLoss(pos_weight = class_weights)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=2,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "      print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "      epoch_loss=0.0    \n",
        "      epoch_acc =0.0\n",
        "      \n",
        "      #train the model\n",
        "      model.train()\n",
        "      \n",
        "      batch_iteration = 0\n",
        "      for i, data in enumerate(dataloadingfortrain, 0):\n",
        "        try:\n",
        "\n",
        "          image_in, label_in = data\n",
        "          optimizer.zero_grad()\n",
        "    \n",
        "          \n",
        "          label_in= label_in.to(device)\n",
        "\n",
        "          \n",
        "          train_output,train_output2 = model1(image_in)\n",
        "          train_output[train_output<thres] =torch.tensor([0], dtype= torch.float32).to(device)\n",
        "\n",
        "          train_output[train_output>=thres] =torch.tensor([1], dtype= torch.float32).to(device)\n",
        "\n",
        "    \n",
        "          train_output = torch.cat((train_output2,train_output), dim =-1)\n",
        "\n",
        "    \n",
        "          train_output = model(train_output)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "          label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "            \n",
        "          loss = criterion(train_output, label_in)\n",
        "          \n",
        "          prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "          \n",
        "          t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=True)\n",
        "          train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "          train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "          epoch_loss += batchloss\n",
        "          epoch_acc += t_acc\n",
        "          count = i\n",
        "          \n",
        "          if i % 500 == 499:\n",
        "\n",
        "            print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "        except ValueError: \n",
        "\n",
        "          print(prediction.detach().cpu().numpy())      \n",
        "\n",
        "          print(np.round(prediction.detach().cpu().numpy()))           \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      train_pred = stack(train_pred)\n",
        "      train_truth = stack(train_truth)\n",
        "      print(\"epoch average auc: \", roc_auc_score(train_truth, train_pred))\n",
        "      print(\"epoch average loss: \", epoch_loss/(len(train_patient)))\n",
        "      train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "      train_loss.append(epoch_loss/(len(train_patient)))\n",
        "      \n",
        "      \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "\n",
        "          \n",
        "\n",
        "        \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "\n",
        "          val_output,val_output2 = model1(v_image_in)\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "          val_output[val_output<thres] =0.0\n",
        "          val_output[val_output>=thres] =1.0\n",
        "\n",
        "          val_output = torch.cat((val_output2,val_output), dim =-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          val_output = model(val_output)\n",
        "\n",
        "    \n",
        "        \n",
        "      \n",
        "          v_label_in=v_label_in.view(-1, 1).type_as(val_output)\n",
        "                \n",
        "          \n",
        "          \n",
        "      \n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "        scheduler.step(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  temp_list = pd.DataFrame({'train_roc_auc' : train_roc_auc,\n",
        "                                  'train_loss' : train_loss,\n",
        "                                  'val_roc_auc' : val_roc_auc,\n",
        "                                  'val_loss' : val_loss,\n",
        "                                  }, \n",
        "                                  columns=['train_roc_auc','train_loss', 'val_roc_auc','val_loss' ])\n",
        "\n",
        "  temp_list.to_csv(\"/content/EfficientNetB4_and_BILSTM_folderNo._{}.csv\".format(time), index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q62yJXvPsPyv"
      },
      "source": [
        "#Section 3 Training using image feature and personal information of patients (gender,age etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_1nxHrQsSNw"
      },
      "source": [
        "##3.1 Dataloading set up & hyperparameter control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12UjSBLXsU7G"
      },
      "outputs": [],
      "source": [
        "# Data loading with personal information for patient-level classification\n",
        "\n",
        "\n",
        "class CustomImageDataset2(Dataset):\n",
        "    def __init__(self, patient_list, img_dir, transform=None, target_transform=None):\n",
        "        self.patient_list = patient_list\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      total = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]].tolist()\n",
        "      malignant = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]][full_train[\"target\"] == 1].tolist()\n",
        "      temp = full_train[\"image_name\"][full_train[\"image_name\"].isin(malignant) == False][full_train[\"patient_id\"]== self.patient_list[idx]].tolist()\n",
        "      img_list =[]\n",
        "      if len(malignant) >=pic:\n",
        "        \n",
        "        img_list.extend(malignant[0:pic])\n",
        "      else:\n",
        "        if len(temp)>= pic-len(malignant):\n",
        "          img_list.extend(malignant)\n",
        "          \n",
        "          img_list.extend(temp[0:pic-len(malignant)])\n",
        "        else:\n",
        "          img_list.extend(temp)\n",
        "          for i in range(pic-len(malignant)-len(temp)):\n",
        "            img_list.extend([total[0]])\n",
        "\n",
        "\n",
        "      if len(img_list)!=pic:\n",
        "        for i in range(pic-len(img_list)):\n",
        "          img_list.extend([total[0]])\n",
        "\n",
        "        \n",
        "      img_labels = full_train[\"target\"][full_train[\"image_name\"].isin(img_list)].tolist()\n",
        "\n",
        "\n",
        "      if len(malignant)> 0:\n",
        "        pat_label = torch.tensor([1], dtype= torch.float32) \n",
        "      else:\n",
        "        pat_label = torch.tensor([0], dtype= torch.float32)\n",
        "\n",
        "\n",
        "      patient_condition=[]\n",
        "      patient_age = [full_train[\"age_group\"][full_train[\"image_name\"] == im] for im in img_list]\n",
        "      patient_sex = [full_train[\"sex\"][full_train[\"image_name\"]== im] for im in img_list]\n",
        "      lesion_location = [full_train[\"anatom_site_general_challenge\"][full_train[\"image_name\"]== im] for im in img_list]\n",
        "      patient_age = np.array(onehot(patient_age,10))\n",
        "      patient_sex = np.array(onehot(patient_sex,3))\n",
        "      lesion_location = np.array(onehot(lesion_location,6))\n",
        "\n",
        "      patient_condition= np.concatenate((patient_age,patient_sex),1)\n",
        "      patient_condition= np.concatenate((patient_condition,lesion_location),1)\n",
        "      if len(patient_condition)!=pic:\n",
        "        use = np.zeros(19)\n",
        "      for i in range(pic-len(patient_condition)):\n",
        "        patient_condition=np.vstack((patient_condition, use))\n",
        "\n",
        "\n",
        "\n",
        "      img_paths = [os.path.join(self.img_dir, i +\".png\") for i in img_list]\n",
        "      images = [cv2.imread(img_path) for img_path in img_paths]\n",
        "\n",
        "      if self.transform is not None:\n",
        "          images = [self.transform(image) for image in images]\n",
        "\n",
        "      return images, pat_label, patient_condition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCot98letD9C"
      },
      "source": [
        "##3.2 Training using model: EfficientNetB4 + Bi-directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suT5RBdIFnMv"
      },
      "outputs": [],
      "source": [
        "# LSTM \n",
        "\n",
        "class Bi_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Bi_LSTM, self).__init__()\n",
        " \n",
        "        self.lstm = nn.LSTM(n_input,n_hidden, num_layers = 2, batch_first =True, bidirectional=True)\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "                \n",
        "                nn.Linear(n_hidden*2,1024),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(1024,512),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(512,256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(256,n_class)\n",
        "                \n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "              \n",
        "        lstm_out, (h_n,c_n) = self.lstm(x)\n",
        "\n",
        "        hidden_out =torch.cat((h_n[0,:,:],h_n[1,:,:]),1)\n",
        "        z = self.predictor(hidden_out)\n",
        "        z = torch.flatten(z)\n",
        "        z = z.view(-1,1)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6bNoTKQFnMv"
      },
      "outputs": [],
      "source": [
        "# combine personal information with image prediction and feature.\n",
        "\n",
        "class Final_model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Final_model, self).__init__()\n",
        "    self.CNN = CON\n",
        "\n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, image, metadata):\n",
        "    feature_record=[]\n",
        "    feature_record2=[]\n",
        "\n",
        "    for img, meta in zip(image,metadata):\n",
        "      \n",
        "      img = img.to(device)\n",
        "\n",
        " \n",
        "      feature = self.CNN(img)\n",
        "      feature2= self.CNN.extract_features(img)\n",
        "      feature2 = self.CNN._avg_pooling(feature2)\n",
        " \n",
        "\n",
        "      feature2 = torch.flatten(feature2,1)\n",
        "\n",
        "  \n",
        "\n",
        "      feature = self.sig(feature)\n",
        "\n",
        "      feature = feature.view(-1, 1)\n",
        "      meta = meta.view(-1,19)\n",
        "\n",
        "      feature2 = torch.cat((feature2,meta),1)\n",
        "\n",
        "      \n",
        "      feature_shape = feature.shape[1]\n",
        "      feature_record.append(feature)\n",
        "      feature_shape2 = feature2.shape[1]\n",
        "      feature_record2.append(feature2)\n",
        "      \n",
        "\n",
        "    feature_record= torch.stack(feature_record).reshape(-1,pic,feature_shape)\n",
        "    feature_record2= torch.stack(feature_record2).reshape(-1,pic,feature_shape2)\n",
        "    \n",
        "    \n",
        "    return feature_record, feature_record2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAcbwoIytGub"
      },
      "outputs": [],
      "source": [
        "time = 0\n",
        "for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "\n",
        "  time +=1\n",
        "  # if time <3:\n",
        "  #   continue\n",
        "  # CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "  # num_ftrs = CON._fc.in_features\n",
        "  # CON._fc = nn.Linear(num_ftrs, 1)\n",
        "  # CON._fc.require_grad = True\n",
        "\n",
        "  # RES = models.resnet50(pretrained=True)\n",
        "  # R_num_ftrs =RES.fc.in_features\n",
        "  # RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "  # RES.fc.require_grad = True\n",
        "\n",
        "  train_patient = []\n",
        "  val_patient = []  \n",
        "  \n",
        "  print(\"this is folder No. \", time)\n",
        "  tep = []\n",
        "  for i in test_index:\n",
        "    tep.append(Full_patient_list[i])\n",
        "    val_patient.append(Full_patient_list[i])\n",
        "  for_val = full_train[full_train['patient_id'].isin(tep)==True]\n",
        "  for_train = full_train[full_train['patient_id'].isin(tep)==False]\n",
        "  for j in train_index:\n",
        "    train_patient.append(Full_patient_list[j])\n",
        "  ones = len(for_train[for_train['target']==1])\n",
        "  zeros = len(for_train)-ones\n",
        "  a = np.zeros(zeros)\n",
        "  b = np.ones(ones)\n",
        "  c = np.concatenate((a,b))\n",
        "  random.shuffle(c)\n",
        "\n",
        "  class_weights=sklearn.utils.class_weight.compute_class_weight('balanced',classes = np.unique(c),y=c)\n",
        "  class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "  class_weights = class_weights[1]/class_weights[0]\n",
        "\n",
        "  batch_size = 30\n",
        "  train_data_cleaned = CustomImageDataset(for_train, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset(for_val, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "  # # Fine-tune efficientNet CNNs\n",
        "  # print('Fine-tune efficientNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = CON\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  # torch.save(model, 'EfficientNetB4_pretrained_final.pt')\n",
        "\n",
        "  # # Fine-tune ResNet CNNs\n",
        "  # print('Fine-tune ResNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = RES\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "\n",
        "  # torch.save(model, 'ResNet50_pretrained_Final.pt')\n",
        "\n",
        "  CON = torch.load(\"/content/model/EfficientNetB4_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  RESNET = torch.load(\"/content/model/ResNet50_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  ## EfficientNetB4\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = CON\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  thres, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  \n",
        "  ## ResNet50\n",
        "  print('getting ResNet50 threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = RESNET\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "  \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "                         \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val)))\n",
        "\n",
        "  thres2, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "\n",
        "  batch_size = 1\n",
        "  pic = 20\n",
        "  train_data_cleaned = CustomImageDataset2(train_patient, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset2(val_patient, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  n_class = 1\n",
        "  batch_size =1\n",
        "  n_input = 1793+19\n",
        "  n_hidden = 2048\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "  # EfficientNetB4 + Bi-directional LSTM with meta info 5 PIC\n",
        "  print(\"Training model EfficientNetB4 + Bi-directional LSTM with meta info 5 PIC\")\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model1 = Final_model().to(device)\n",
        "\n",
        "  model = Bi_LSTM().to(device)\n",
        "\n",
        "  train_roc_auc =[]\n",
        "\n",
        "  train_loss=[]\n",
        "\n",
        "  val_roc_auc=[]\n",
        "\n",
        "  val_loss=[]\n",
        "\n",
        "  val_f1 = []\n",
        "\n",
        "  train_f1 = []\n",
        "\n",
        "\n",
        "  class_weights = class_weights.to(device)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  criterion = nn.BCEWithLogitsLoss(pos_weight = class_weights)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=2,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "  model1.eval()\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "      print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "      epoch_loss=0.0    \n",
        "      epoch_acc =0.0\n",
        "      \n",
        "      #train the model\n",
        "      model.train()\n",
        "      \n",
        "      batch_iteration = 0\n",
        "      for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "        image_in, label_in, meta = data\n",
        "        optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "        label_in= label_in.to(device)\n",
        "\n",
        "        meta= meta.to(device)\n",
        "      \n",
        "        meta= meta.view(pic,-1,19)\n",
        "        \n",
        "\n",
        "        pred, out = model1(image_in, meta)\n",
        "    \n",
        "        pred[pred<thres] =0\n",
        "        pred[pred>=thres] =1\n",
        "        train_output = torch.cat((out,pred), dim =-1)\n",
        "        train_output = model(train_output.float())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "  \n",
        "      \n",
        "        loss = criterion(train_output, label_in)\n",
        "        \n",
        "        prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        batchloss = loss.item()\n",
        "        t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "        train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "        train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "        epoch_loss += batchloss\n",
        "        epoch_acc += t_acc\n",
        "        count = i\n",
        "        \n",
        "        if i % 500 == 499:\n",
        "\n",
        "          print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "          \n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "      train_pred = stack(train_pred)\n",
        "      train_truth = stack(train_truth)\n",
        "      print(\"epoch average auc: \", roc_auc_score(train_truth, train_pred))\n",
        "      print(\"epoch average loss: \", epoch_loss/(len(train_patient)))\n",
        "\n",
        "      train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "\n",
        "      train_loss.append(epoch_loss/(len(train_patient)))\n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "          v_image_in, v_label_in, v_meta = dat\n",
        "          \n",
        "          \n",
        "\n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_meta= v_meta.to(device)\n",
        "\n",
        "          v_meta =v_meta.view(pic,-1,19)\n",
        "          \n",
        "  \n",
        "          pred, out = model1(v_image_in, v_meta)\n",
        "          pred[pred<thres] =0\n",
        "          pred[pred>=thres] =1\n",
        "          val_output = torch.cat((out,pred), dim =-1)\n",
        "          val_output = model(val_output.float())\n",
        "\n",
        "      \n",
        "          v_label_in=v_label_in.view(-1, 1).type_as(val_output)\n",
        "                \n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "      \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "      print(\"roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "      val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "      val_loss.append(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "      scheduler.step(val_epoch_loss/(len(val_patient))) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  temp_list = pd.DataFrame({'train_roc_auc' : train_roc_auc,\n",
        "                                  'train_loss' : train_loss,\n",
        "                                  'val_roc_auc' : val_roc_auc,\n",
        "                                  'val_loss' : val_loss,\n",
        "                                  }, \n",
        "                                  columns=['train_roc_auc','train_loss', 'val_roc_auc','val_loss' ])\n",
        "\n",
        "  temp_list.to_csv(\"/content/EfficientNetB4_and_BILSTM_with_metainfo_folderNo._{}.csv\".format(time), index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYpANbDAtn_C"
      },
      "source": [
        "##3.3 Training using model: EfficientNetB4 + Bi-directional LSTM with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fsfc6ixW6pbA"
      },
      "outputs": [],
      "source": [
        "## Bi-LSTM with attention mechanism\n",
        "\n",
        "class Bi_LSTM_attention(nn.Module):\n",
        "    def __init__(self, n_input, n_hidden):\n",
        "        super(Bi_LSTM_attention, self).__init__()\n",
        "\n",
        "        self.ATTN_TYPE_DOT_PRODUCT = \"Dot Product\"\n",
        "        self.ATTN_TYPE_SCALE_DOT_PRODUCT = \"Scale Dot Product\"\n",
        "        self.ATTN_TYPE_GENERAL_DOT_PRODUCT = \"General Dot Product\"\n",
        "        self.n_input=n_input\n",
        "        self.n_hidden= n_hidden\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        self.lstm_encoder = nn.LSTM(n_input, n_hidden // 2,\n",
        "                                  num_layers=1,batch_first =True, bidirectional=True)\n",
        "        \n",
        "        self.lstm_decoder = nn.LSTM(n_input, n_hidden // 2,\n",
        "                                  num_layers=1,batch_first =True, bidirectional=True)\n",
        "        \n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "                nn.Linear(self.n_hidden*pic*2,512),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(512,256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(256,128),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(128,n_class)\n",
        "                \n",
        "            )\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "      return (torch.randn(2, 1, self.n_hidden // 2).to(device),\n",
        "              torch.randn(2, 1, self.n_hidden // 2).to(device))\n",
        "    \n",
        "  \n",
        "    \n",
        "    def _cal_attention(self, hidden, encoder_hiddens, method):\n",
        "\n",
        "        if method == self.ATTN_TYPE_DOT_PRODUCT:\n",
        "          attn_weights = F.softmax(torch.matmul(hidden.squeeze(1), encoder_hiddens.squeeze(1).T),dim=-1)\n",
        "          attn_output = torch.matmul(attn_weights, encoder_hiddens.squeeze(1))\n",
        "          concat_output = torch.cat((attn_output, hidden.squeeze(1)), -1)\n",
        "          concat_output = concat_output.unsqueeze(1)\n",
        "\n",
        "\n",
        "        elif method == self.ATTN_TYPE_SCALE_DOT_PRODUCT:\n",
        "          attn_weights = F.softmax(torch.matmul(hidden.squeeze(1), encoder_hiddens.squeeze(1).T)/np.sqrt(self.n_hidden),dim=-1)\n",
        "          attn_output = torch.matmul(attn_weights, encoder_hiddens.squeeze(1))\n",
        "          concat_output = torch.cat((attn_output, hidden.squeeze(1)), -1)\n",
        "          concat_output = concat_output.unsqueeze(1)\n",
        "\n",
        "        elif method == self.ATTN_TYPE_GENERAL_DOT_PRODUCT:\n",
        "          self.att_weight = nn.Parameter(torch.randn(hidden.squeeze(1).shape[1],hidden.squeeze(1).shape[1]))\n",
        "          hidden = torch.matmul(hidden.squeeze(1), self.att_weight).unsqueeze(1)\n",
        "          attn_weights = F.softmax(torch.matmul(hidden.squeeze(1), encoder_hiddens.squeeze(1).T),dim=-1)\n",
        "          attn_output = torch.matmul(attn_weights, encoder_hiddens.squeeze(1))\n",
        "          concat_output = torch.cat((attn_output, hidden.squeeze(1)), -1)\n",
        "          concat_output = concat_output.unsqueeze(1)\n",
        "        \n",
        "        return concat_output\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      self.hidden = self.init_hidden()\n",
        "      encoder_out, self.hidden  = self.lstm_encoder(x, self.hidden) \n",
        "      (h_n, c_n) = self.hidden\n",
        "      lstm_out, self.hidden  = self.lstm_decoder(x, self.hidden)\n",
        "      hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)     \n",
        "      attention_output = self._cal_attention(lstm_out, hidden_out,self.ATTN_TYPE_DOT_PRODUCT)\n",
        "\n",
        "      attention_output = attention_output.view(batch_size, self.n_hidden*pic*2)\n",
        "      attention_output = self.dropout(attention_output)\n",
        "                \n",
        "\n",
        "      z = self.predictor(attention_output)\n",
        "      return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtkASmocmQdo"
      },
      "outputs": [],
      "source": [
        "# combine personal information with image prediction and feature\n",
        "\n",
        "class Final_model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Final_model, self).__init__()\n",
        "    self.CNN = CON\n",
        "\n",
        "\n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        " \n",
        "\n",
        "  def forward(self, image, metadata):\n",
        "    feature_record=[]\n",
        "    feature_record2=[]\n",
        "\n",
        "    for img, meta in zip(image,metadata):\n",
        "      \n",
        "      img = img.to(device)\n",
        "\n",
        " \n",
        "      feature = self.CNN(img)\n",
        "      feature2= self.CNN.extract_features(img)\n",
        "      feature2 = self.CNN._avg_pooling(feature2)\n",
        "\n",
        "\n",
        "      feature2 = torch.flatten(feature2,1)\n",
        "\n",
        "  \n",
        "\n",
        "      feature = self.sig(feature)\n",
        "\n",
        "      feature = feature.view(-1, 1)\n",
        "      meta = meta.view(-1,19)\n",
        "\n",
        "      feature2 = torch.cat((feature2,meta),1)\n",
        "\n",
        "      \n",
        "      feature_shape = feature.shape[1]\n",
        "      feature_record.append(feature)\n",
        "      feature_shape2 = feature2.shape[1]\n",
        "      feature_record2.append(feature2)\n",
        "      \n",
        "\n",
        "    feature_record= torch.stack(feature_record).reshape(-1,pic,feature_shape)\n",
        "    feature_record2= torch.stack(feature_record2).reshape(-1,pic,feature_shape2)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    return feature_record, feature_record2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5or0IJoGtpDP"
      },
      "outputs": [],
      "source": [
        "time = 0\n",
        "for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "  time +=1\n",
        "  # if time < 5:\n",
        "  #   continue\n",
        "  # CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "  # num_ftrs = CON._fc.in_features\n",
        "  # CON._fc = nn.Linear(num_ftrs, 1)\n",
        "  # CON._fc.require_grad = True\n",
        "\n",
        "  # RES = models.resnet50(pretrained=True)\n",
        "  # R_num_ftrs =RES.fc.in_features\n",
        "  # RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "  # RES.fc.require_grad = True\n",
        "\n",
        "  train_patient = []\n",
        "  val_patient = []  \n",
        "  \n",
        "  print(\"this is folder No. \", time)\n",
        "  tep = []\n",
        "  for i in test_index:\n",
        "    tep.append(Full_patient_list[i])\n",
        "    val_patient.append(Full_patient_list[i])\n",
        "  for_val = full_train[full_train['patient_id'].isin(tep)==True]\n",
        "  for_train = full_train[full_train['patient_id'].isin(tep)==False]\n",
        "  for j in train_index:\n",
        "    train_patient.append(Full_patient_list[j])\n",
        "  ones = len(for_train[for_train['target']==1])\n",
        "  zeros = len(for_train)-ones\n",
        "  a = np.zeros(zeros)\n",
        "  b = np.ones(ones)\n",
        "  c = np.concatenate((a,b))\n",
        "  random.shuffle(c)\n",
        "\n",
        "  class_weights=sklearn.utils.class_weight.compute_class_weight('balanced',classes = np.unique(c),y=c)\n",
        "  class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "  class_weights = class_weights[1]/class_weights[0]\n",
        "\n",
        "  batch_size = 30\n",
        "  train_data_cleaned = CustomImageDataset(for_train, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset(for_val, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "  # # Fine-tune efficientNet CNNs\n",
        "  # print('Fine-tune efficientNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = CON\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  # torch.save(model, 'EfficientNetB4_pretrained_final.pt')\n",
        "\n",
        "  # # Fine-tune ResNet CNNs\n",
        "  # print('Fine-tune ResNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = RES\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "\n",
        "  # torch.save(model, 'ResNet50_pretrained_Final.pt')\n",
        "\n",
        "  CON = torch.load(\"/content/model/EfficientNetB4_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  RESNET = torch.load(\"/content/model/ResNet50_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  ## EfficientNetB4\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = CON\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  thres, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  \n",
        "  ## ResNet50\n",
        "  print('getting ResNet50 threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = RESNET\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "  \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "                         \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val)))\n",
        "\n",
        "  thres2, _ = threshold(ground_truth,final_prediction)\n",
        "  # EfficientNetB4 and Bi-directional LSTM\n",
        "  print(\"Training model EfficientNetB4 and Bi-directional LSTM\")\n",
        "  print(\"this is folder No. \", time)\n",
        "\n",
        "  batch_size = 1\n",
        "  pic = 20\n",
        "  train_data_cleaned = CustomImageDataset2(train_patient, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset2(val_patient, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  n_class = 1\n",
        "  batch_size =1\n",
        "  n_input = 1793+19\n",
        "  n_hidden = 2048\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "  ## EfficientNetB4 + Bi-directional LSTM with Attention with personal information 5 images per patient\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model1 = Final_model().to(device)\n",
        "\n",
        "  model = Bi_LSTM_attention(n_input,n_hidden).to(device)\n",
        "\n",
        "  train_roc_auc =[]\n",
        "\n",
        "  train_loss=[]\n",
        "\n",
        "  val_roc_auc=[]\n",
        "\n",
        "  val_loss=[]\n",
        "\n",
        "  val_f1 = []\n",
        "\n",
        "  train_f1 = []\n",
        "\n",
        "  class_weights = class_weights.to(device)\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  criterion = nn.BCEWithLogitsLoss(pos_weight = class_weights)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=2,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "  model1.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "      print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "      epoch_loss=0.0    \n",
        "      epoch_acc =0.0\n",
        "      \n",
        "      #train the model\n",
        "      model.train()\n",
        "      \n",
        "      batch_iteration = 0\n",
        "      for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "        image_in, label_in, meta = data\n",
        "        optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "        label_in= label_in.to(device)\n",
        "\n",
        "        meta= meta.to(device)\n",
        "      \n",
        "        meta= meta.view(pic,-1,19)\n",
        "        \n",
        "        pred, out = model1(image_in, meta)\n",
        "\n",
        "\n",
        "        pred[pred<thres] =0\n",
        "        pred[pred>=thres] =1\n",
        "        train_output = torch.cat((out,pred), dim =-1)\n",
        "        train_output = model(train_output.float())\n",
        "\n",
        "\n",
        "\n",
        "        label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "  \n",
        "      \n",
        "        loss = criterion(train_output, label_in)\n",
        "        \n",
        "        prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        batchloss = loss.item()\n",
        "        t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "        train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "        train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "        epoch_loss += batchloss\n",
        "        epoch_acc += t_acc\n",
        "        count = i\n",
        "        \n",
        "        if i % 500 == 499:\n",
        "\n",
        "          print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "          \n",
        "\n",
        "      train_pred = stack(train_pred)\n",
        "      train_truth = stack(train_truth)\n",
        "      print(\"epoch average auc: \", roc_auc_score(train_truth, train_pred))\n",
        "      print(\"epoch average loss: \", epoch_loss/(len(train_patient)))\n",
        "\n",
        "      train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "\n",
        "      train_loss.append(epoch_loss/(len(train_patient)))\n",
        "    \n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "          v_image_in, v_label_in, v_meta = dat\n",
        "          \n",
        "          \n",
        "\n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_meta= v_meta.to(device)\n",
        "\n",
        "          v_meta =v_meta.view(pic,-1,19)\n",
        "          \n",
        "          pred, out = model1(v_image_in, v_meta)\n",
        "\n",
        "          pred[pred<thres] =0\n",
        "          pred[pred>=thres] =1\n",
        "          val_output = torch.cat((out,pred), dim =-1)\n",
        "          val_output = model(val_output.float())\n",
        "\n",
        "\n",
        "      \n",
        "          v_label_in=v_label_in.view(-1, 1).type_as(val_output)\n",
        "                \n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "        \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "      print(\"roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "      val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "      val_loss.append(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "      scheduler.step(val_epoch_loss/(len(val_patient))) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  temp_list = pd.DataFrame({'train_roc_auc' : train_roc_auc,\n",
        "                                  'train_loss' : train_loss,\n",
        "                                  'val_roc_auc' : val_roc_auc,\n",
        "                                  'val_loss' : val_loss,\n",
        "                                  }, \n",
        "                                  columns=['train_roc_auc','train_loss', 'val_roc_auc','val_loss' ])\n",
        "\n",
        "  temp_list.to_csv(\"/content/EfficientNetB4_and_BILSTM_Attention_with_metainfo_folderNo._{}.csv\".format(time), index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt-Nj6Aut_tR"
      },
      "source": [
        "##3.4 Training using EfficientNetB4 + ResNet50 + Bi-directional LSTM with Attention and personal information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jYsQxbEdIB-"
      },
      "outputs": [],
      "source": [
        "# Data loading with personal information for patient-level classification\n",
        "\n",
        "\n",
        "class CustomImageDataset2(Dataset):\n",
        "    def __init__(self, patient_list, img_dir, transform=None, target_transform=None):\n",
        "        self.patient_list = patient_list\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      total = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]].tolist()\n",
        "      malignant = full_train[\"image_name\"][full_train[\"patient_id\"] == self.patient_list[idx]][full_train[\"target\"] == 1].tolist()\n",
        "      temp = full_train[\"image_name\"][full_train[\"image_name\"].isin(malignant) == False][full_train[\"patient_id\"]== self.patient_list[idx]].tolist()\n",
        "      img_list =[]\n",
        "      if len(malignant) >=pic:\n",
        "        \n",
        "        img_list.extend(malignant[0:pic])\n",
        "      else:\n",
        "        if len(temp)>= pic-len(malignant):\n",
        "          img_list.extend(malignant)\n",
        "          \n",
        "          img_list.extend(temp[0:pic-len(malignant)])\n",
        "        else:\n",
        "          img_list.extend(temp)\n",
        "          for i in range(pic-len(malignant)-len(temp)):\n",
        "            img_list.extend([total[0]])\n",
        "\n",
        "\n",
        "      if len(img_list)!=pic:\n",
        "        for i in range(pic-len(img_list)):\n",
        "          img_list.extend([total[0]])\n",
        "\n",
        "        \n",
        "      img_labels = full_train[\"target\"][full_train[\"image_name\"].isin(img_list)].tolist()\n",
        "\n",
        "\n",
        "      if len(malignant)> 0:\n",
        "        pat_label = torch.tensor([1], dtype= torch.float32) \n",
        "      else:\n",
        "        pat_label = torch.tensor([0], dtype= torch.float32)\n",
        "\n",
        "\n",
        "      patient_condition=[]\n",
        "      patient_age = [full_train[\"age_group\"][full_train[\"image_name\"] == im] for im in img_list]\n",
        "      patient_sex = [full_train[\"sex\"][full_train[\"image_name\"]== im] for im in img_list]\n",
        "      lesion_location = [full_train[\"anatom_site_general_challenge\"][full_train[\"image_name\"]== im] for im in img_list]\n",
        "      patient_age = np.array(onehot(patient_age,10))\n",
        "      patient_sex = np.array(onehot(patient_sex,3))\n",
        "      lesion_location = np.array(onehot(lesion_location,6))\n",
        "\n",
        "      patient_condition= np.concatenate((patient_age,patient_sex),1)\n",
        "      patient_condition= np.concatenate((patient_condition,lesion_location),1)\n",
        "      if len(patient_condition)!=pic:\n",
        "        use = np.zeros(19)\n",
        "      for i in range(pic-len(patient_condition)):\n",
        "        patient_condition=np.vstack((patient_condition, use))\n",
        "\n",
        "\n",
        "\n",
        "      img_paths = [os.path.join(self.img_dir, i +\".png\") for i in img_list]\n",
        "      images = [cv2.imread(img_path) for img_path in img_paths]\n",
        "\n",
        "      if self.transform is not None:\n",
        "          images = [self.transform(image) for image in images]\n",
        "\n",
        "      return images, pat_label, patient_condition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UB3eGceHe1G"
      },
      "outputs": [],
      "source": [
        "## Bi-LSTM with Attention Mechanism\n",
        "class Bi_LSTM_attention(nn.Module):\n",
        "    def __init__(self, n_input, n_hidden):\n",
        "        super(Bi_LSTM_attention, self).__init__()\n",
        "\n",
        "        self.ATTN_TYPE_DOT_PRODUCT = \"Dot Product\"\n",
        "        self.ATTN_TYPE_SCALE_DOT_PRODUCT = \"Scale Dot Product\"\n",
        "        self.ATTN_TYPE_GENERAL_DOT_PRODUCT = \"General Dot Product\"\n",
        "        self.n_input=n_input\n",
        "        self.n_hidden= n_hidden\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "        self.lstm_encoder = nn.LSTM(n_input, n_hidden // 2,\n",
        "                                  num_layers=1,batch_first =True, bidirectional=True)\n",
        "        \n",
        "        self.lstm_decoder = nn.LSTM(n_input, n_hidden // 2,\n",
        "                                  num_layers=1,batch_first =True, bidirectional=True)\n",
        "        \n",
        "        \n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "                nn.Linear(self.n_hidden*pic*2,512),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(512,256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(256,128),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(128,n_class)\n",
        "                \n",
        "            )\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "      return (torch.randn(2, 1, self.n_hidden // 2).to(device),\n",
        "              torch.randn(2, 1, self.n_hidden // 2).to(device))\n",
        "    \n",
        "  \n",
        "    \n",
        "    def _cal_attention(self, hidden, encoder_hiddens, method):\n",
        "\n",
        "        if method == self.ATTN_TYPE_DOT_PRODUCT:\n",
        "          attn_weights = F.softmax(torch.matmul(hidden.squeeze(1), encoder_hiddens.squeeze(1).T),dim=-1)\n",
        "          attn_output = torch.matmul(attn_weights, encoder_hiddens.squeeze(1))\n",
        "          concat_output = torch.cat((attn_output, hidden.squeeze(1)), -1)\n",
        "          concat_output = concat_output.unsqueeze(1)\n",
        "\n",
        "\n",
        "        elif method == self.ATTN_TYPE_SCALE_DOT_PRODUCT:\n",
        "          attn_weights = F.softmax(torch.matmul(hidden.squeeze(1), encoder_hiddens.squeeze(1).T)/np.sqrt(self.n_hidden),dim=-1)\n",
        "          attn_output = torch.matmul(attn_weights, encoder_hiddens.squeeze(1))\n",
        "          concat_output = torch.cat((attn_output, hidden.squeeze(1)), -1)\n",
        "          concat_output = concat_output.unsqueeze(1)\n",
        "\n",
        "        elif method == self.ATTN_TYPE_GENERAL_DOT_PRODUCT:\n",
        "          self.att_weight = nn.Parameter(torch.randn(hidden.squeeze(1).shape[1],hidden.squeeze(1).shape[1]))\n",
        "          hidden = torch.matmul(hidden.squeeze(1), self.att_weight).unsqueeze(1)\n",
        "          attn_weights = F.softmax(torch.matmul(hidden.squeeze(1), encoder_hiddens.squeeze(1).T),dim=-1)\n",
        "          attn_output = torch.matmul(attn_weights, encoder_hiddens.squeeze(1))\n",
        "          concat_output = torch.cat((attn_output, hidden.squeeze(1)), -1)\n",
        "          concat_output = concat_output.unsqueeze(1)\n",
        "        \n",
        "        return concat_output\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      self.hidden = self.init_hidden()\n",
        "      encoder_out, self.hidden  = self.lstm_encoder(x, self.hidden) \n",
        "      (h_n, c_n) = self.hidden\n",
        "      lstm_out, self.hidden  = self.lstm_decoder(x, self.hidden)\n",
        "      hidden_out = torch.cat((h_n[0,:,:],h_n[1,:,:]),1)     \n",
        "      attention_output = self._cal_attention(lstm_out, hidden_out,self.ATTN_TYPE_DOT_PRODUCT)\n",
        "\n",
        "      attention_output = attention_output.view(batch_size, self.n_hidden*pic*2)\n",
        "      attention_output = self.dropout(attention_output)\n",
        "                \n",
        "\n",
        "      z = self.predictor(attention_output)\n",
        "      return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1fWb-VJHrcR"
      },
      "outputs": [],
      "source": [
        "# Set up classification and feature extraction using EfficientB4\n",
        "\n",
        "class Final_model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Final_model, self).__init__()\n",
        "    self.CNN = CON\n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        "  \n",
        "\n",
        "  def forward(self, image, metadata):\n",
        "    feature_record=[]\n",
        "    feature_record2=[]\n",
        "\n",
        "    for img, meta in zip(image,metadata):\n",
        "      \n",
        "      img = img.to(device)\n",
        "\n",
        " \n",
        "      feature = self.CNN(img)\n",
        "      feature2= self.CNN.extract_features(img)\n",
        "      feature2 = self.CNN._avg_pooling(feature2)\n",
        "\n",
        "\n",
        "      feature2 = torch.flatten(feature2,1)\n",
        "\n",
        "  \n",
        "\n",
        "      feature = self.sig(feature)\n",
        "\n",
        "      feature = feature.view(-1, 1)\n",
        "      meta = meta.view(-1,19)\n",
        "\n",
        "      feature2 = torch.cat((feature2,meta),1)\n",
        "\n",
        "      \n",
        "      feature_shape = feature.shape[1]\n",
        "      feature_record.append(feature)\n",
        "      feature_shape2 = feature2.shape[1]\n",
        "      feature_record2.append(feature2)\n",
        "      \n",
        "\n",
        "    feature_record= torch.stack(feature_record).reshape(-1,pic,feature_shape)\n",
        "    feature_record2= torch.stack(feature_record2).reshape(-1,pic,feature_shape2)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    return feature_record, feature_record2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSj0tnhzhplF"
      },
      "outputs": [],
      "source": [
        "# Set up classification and feature extraction using ResNet50\n",
        "\n",
        "class Final_model1(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Final_model1, self).__init__()\n",
        "    self.CNN = RESNET\n",
        " \n",
        "\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  \n",
        "  def forward(self, image):\n",
        "    feature_record=[]\n",
        "    feature_record2=[]\n",
        "\n",
        "\n",
        "    for img in image:\n",
        "      \n",
        "      img = img.to(device)\n",
        "\n",
        " \n",
        "      feature = self.CNN(img)\n",
        " \n",
        "\n",
        "      feature = self.sig(feature)\n",
        "  \n",
        "\n",
        "      feature_shape = feature.shape[1]\n",
        "\n",
        " \n",
        "      feature_record.append(feature)\n",
        "\n",
        "        \n",
        "\n",
        "    feature_record= torch.stack(feature_record).reshape(-1,pic,feature_shape)\n",
        "  \n",
        "    \n",
        "    \n",
        "    return feature_record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nC43kO6tZGF"
      },
      "outputs": [],
      "source": [
        "time = 0\n",
        "for train_index, test_index in kf.split(Full_patient_list, patient_class):\n",
        "  time +=1\n",
        "  # if time <4:\n",
        "  #   continue\n",
        "  # CON = EfficientNet.from_pretrained('efficientnet-b4')\n",
        "  # num_ftrs = CON._fc.in_features\n",
        "  # CON._fc = nn.Linear(num_ftrs, 1)\n",
        "  # CON._fc.require_grad = True\n",
        "\n",
        "  # RES = models.resnet50(pretrained=True)\n",
        "  # R_num_ftrs =RES.fc.in_features\n",
        "  # RES.fc = nn.Linear(R_num_ftrs, 1)\n",
        "  # RES.fc.require_grad = True\n",
        "\n",
        "  train_patient = []\n",
        "  val_patient = []  \n",
        "\n",
        "  print(\"this is folder No. \", time)\n",
        "  tep = []\n",
        "  for i in test_index:\n",
        "    tep.append(Full_patient_list[i])\n",
        "    val_patient.append(Full_patient_list[i])\n",
        "  for_val = full_train[full_train['patient_id'].isin(tep)==True]\n",
        "  for_train = full_train[full_train['patient_id'].isin(tep)==False]\n",
        "  for j in train_index:\n",
        "    train_patient.append(Full_patient_list[j])\n",
        "  ones = len(for_train[for_train['target']==1])\n",
        "  zeros = len(for_train)-ones\n",
        "  a = np.zeros(zeros)\n",
        "  b = np.ones(ones)\n",
        "  c = np.concatenate((a,b))\n",
        "  random.shuffle(c)\n",
        "\n",
        "  class_weights=sklearn.utils.class_weight.compute_class_weight('balanced',classes = np.unique(c),y=c)\n",
        "  class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
        "  class_weights = class_weights[1]/class_weights[0]\n",
        "\n",
        "  batch_size = 30\n",
        "  train_data_cleaned = CustomImageDataset(for_train, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset(for_val, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "  # # Fine-tune efficientNet CNNs\n",
        "  # print('Fine-tune efficientNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = CON\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  # torch.save(model, 'EfficientNetB4_pretrained_final.pt')\n",
        "\n",
        "  # # Fine-tune ResNet CNNs\n",
        "  # print('Fine-tune ResNet CNNs')\n",
        "  # print(\"this is folder No. \", time)\n",
        "  # learning_rate = 0.001\n",
        "  # epochs = 10\n",
        "  # model = RES\n",
        "  # model = model.to(device)\n",
        "\n",
        "  # train_roc_auc = []\n",
        "\n",
        "  # train_loss = []\n",
        "\n",
        "  # val_roc_auc = []\n",
        "\n",
        "  # val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "  #         optimizer,\n",
        "  #         patience=1,\n",
        "  #         factor=0.2,\n",
        "  #         threshold=0.001,\n",
        "  #         mode=\"max\",\n",
        "  #         verbose=True\n",
        "  #     )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # for epoch in range(epochs):\n",
        "  #     train_pred = []\n",
        "  #     train_truth=[]\n",
        "      \n",
        "  #     final_prediction= []\n",
        "  #     ground_truth = []\n",
        "  #     print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "  #     epoch_loss=0.0    \n",
        "  #     epoch_acc =0.0\n",
        "      \n",
        "  #     #train the model\n",
        "  #     model.train()\n",
        "      \n",
        "  #     batch_iteration = 0\n",
        "  #     for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "  #       image_in, label_in = data\n",
        "  #       optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "  #       label_in= label_in.to(device)\n",
        "\n",
        "  #       image_in= image_in.to(device)\n",
        "      \n",
        "        \n",
        "  #       train_output = model(image_in)\n",
        "\n",
        "  \n",
        "\n",
        "  #       label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "\n",
        "      \n",
        "  #       loss = criterion(train_output, label_in)\n",
        "        \n",
        "  #       prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "  #       loss.backward()\n",
        "\n",
        "  #       optimizer.step()\n",
        "        \n",
        "        \n",
        "  #       batchloss = loss.item()\n",
        "  #       t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "  #       train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "  #       train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "  #       epoch_loss += batchloss\n",
        "  #       epoch_acc += t_acc\n",
        "  #       count = i\n",
        "        \n",
        "  #       if i % 100 == 99:\n",
        "\n",
        "  #         print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  #     train_pred = stack(train_pred)\n",
        "  #     train_truth = stack(train_truth)\n",
        "  #     print(\"epoch auc: \", roc_auc_score(train_truth, train_pred))\n",
        "  #     print(\"epoch average loss: \", epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "  #     train_loss.append(epoch_loss/(len(for_train)))\n",
        "\n",
        "  #     model.eval()\n",
        "      \n",
        "  #     val_epoch_loss = 0.0\n",
        "  #     val_epoch_acc = 0.0  \n",
        "  #     with torch.no_grad():\n",
        "  #       for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "  #         v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "  #         v_label_in= v_label_in.to(device)\n",
        "\n",
        "  #         v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "  #         val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "  #         loss = criterion(val_output, v_label_in)\n",
        "\n",
        "  #         v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "  #         batchloss = loss.item()\n",
        "\n",
        "\n",
        "  #         final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "  #         ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "  #         if j % 10 == 9:\n",
        "\n",
        "\n",
        "  #           print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "  #         val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "  #       final_prediction = stack(final_prediction)\n",
        "\n",
        "  #       ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "  #       print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "  #       print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "  #       scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "  #       val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "\n",
        "  # torch.save(model, 'ResNet50_pretrained_Final.pt')\n",
        "\n",
        "\n",
        "  CON = torch.load(\"/content/model/EfficientNetB4_folderNo._{}.pt\".format(time))\n",
        "\n",
        "  RESNET = torch.load(\"/content/model/ResNet50_folderNo._{}.pt\".format(time))\n",
        "\n",
        "\n",
        "\n",
        "  print('getting EfficientNet threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  ## EfficientNetB4\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = CON\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "          \n",
        "          \n",
        "        \n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)\n",
        "\n",
        "          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val))) \n",
        "\n",
        "  thres, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  \n",
        "  ## ResNet50\n",
        "  print('getting ResNet50 threshold')\n",
        "  print(\"this is folder No. \", time)\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model = RESNET\n",
        "  model = model.to(device)\n",
        "\n",
        "  train_roc_auc = []\n",
        "\n",
        "  train_loss = []\n",
        "\n",
        "  val_roc_auc = []\n",
        "\n",
        "  val_loss = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  #criterion = nn.CrossEntropyLoss()\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=1,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "  \n",
        "\n",
        "      model.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "          v_image_in, v_label_in = dat\n",
        "                         \n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_image_in= v_image_in.to(device)          \n",
        "          \n",
        "          val_output = model(v_image_in)\n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "          \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(for_val)))\n",
        "\n",
        "\n",
        "\n",
        "        print(\"validation roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "        scheduler.step(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "        val_loss.append(val_epoch_loss/(len(for_val)))\n",
        "\n",
        "  thres2, _ = threshold(ground_truth,final_prediction)\n",
        "\n",
        "  # EfficientNetB4 and ResNet50 and Bi-directional LSTM with Attention and personal info\n",
        "\n",
        "  print(\"Training model EfficientNetB4 and ResNet50 and Bi-directional LSTM with Attention and personal info\")\n",
        "  print(\"this is folder No. \", time)\n",
        "  batch_size = 1\n",
        "  pic = 15\n",
        "  train_data_cleaned = CustomImageDataset2(train_patient, '/content/train/', train_dat_tran)\n",
        "  val_data_cleaned = CustomImageDataset2(val_patient, '/content/train/', val_dat_tran)\n",
        "  dataloadingfortrain = DataLoader(train_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  dataloadingforval = DataLoader(val_data_cleaned, batch_size = batch_size, shuffle = True)\n",
        "  # Here we add extra one to n_input, this is the extra classification made by ResNet 50\n",
        "\n",
        "  n_class = 1\n",
        "  batch_size =1\n",
        "  n_input = 1793+20\n",
        "  n_hidden = 2048\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  ## Training using EfficientNetB4 + ResNet50 + Bi-directional LSTM with Attention and personal information 5 images per patient\n",
        "  print(\"training ultimate model\")\n",
        "  learning_rate = 0.001\n",
        "  epochs = 1\n",
        "  model1 = Final_model().to(device)\n",
        "  model2 = Final_model1().to(device)\n",
        "  LSTM = Bi_LSTM_attention(n_input,n_hidden).to(device)\n",
        "\n",
        "  train_roc_auc =[]\n",
        "\n",
        "  train_loss=[]\n",
        "\n",
        "  val_roc_auc=[]\n",
        "\n",
        "  val_loss=[]\n",
        "\n",
        "  val_f1 = []\n",
        "\n",
        "  train_f1 = []\n",
        "\n",
        "  class_weights = class_weights.to(device)\n",
        "\n",
        "  #optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  #optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  optimizer = torch.optim.SGD(LSTM.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "  criterion = nn.BCEWithLogitsLoss(pos_weight = class_weights)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "          optimizer,\n",
        "          patience=2,\n",
        "          factor=0.2,\n",
        "          threshold=0.001,\n",
        "          mode=\"max\",\n",
        "          verbose=True\n",
        "      )\n",
        "\n",
        "  model1.eval()\n",
        "  model2.eval()\n",
        "\n",
        "\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train_pred = []\n",
        "      train_truth=[]\n",
        "      \n",
        "      final_prediction= []\n",
        "      ground_truth = []\n",
        "      print(\"this is epoch \", epoch+1, \"running\")\n",
        "      \n",
        "      epoch_loss=0.0    \n",
        "      epoch_acc =0.0\n",
        "      \n",
        "      #train the model\n",
        "      LSTM.train()\n",
        "      \n",
        "      batch_iteration = 0\n",
        "      for i, data in enumerate(dataloadingfortrain, 0):\n",
        "\n",
        "        image_in, label_in, meta = data\n",
        "        optimizer.zero_grad()\n",
        "  \n",
        "        \n",
        "        label_in= label_in.to(device)\n",
        "\n",
        "        meta= meta.to(device)\n",
        "      \n",
        "        meta= meta.view(pic,-1,19)\n",
        "        \n",
        "        pred, out = model1(image_in, meta)\n",
        "\n",
        "        pred2 = model2(image_in)      \n",
        "        pred[pred<thres] =0\n",
        "        pred[pred>=thres] =1\n",
        "        pred2[pred2<thres2] =0\n",
        "        pred2[pred2>=thres2] =1\n",
        "        pred = torch.cat((pred,pred2),dim=-1)\n",
        "        train_output = torch.cat((out,pred), dim =-1)\n",
        "        train_output = LSTM(train_output.float())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        label_in=label_in.view(-1, 1).type_as(train_output)\n",
        "  \n",
        "      \n",
        "        loss = criterion(train_output, label_in)\n",
        "        \n",
        "        prediction = torch.sigmoid(train_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        \n",
        "        # teet = np.any(np.isnan(np.round(prediction.detach().cpu().numpy())))\n",
        "        # if teet == True:\n",
        "        #   print(np.round(prediction.detach().cpu().numpy()))\n",
        "        #   print(prediction.detach().cpu().numpy())\n",
        "        batchloss = loss.item()\n",
        "        t_acc = accuracy_score(label_in.cpu().numpy() , np.round(prediction.detach().cpu().numpy()),normalize=False)\n",
        "        train_pred.append(prediction.detach().cpu().numpy())\n",
        "\n",
        "        train_truth.append(label_in.cpu().numpy())\n",
        "\n",
        "        epoch_loss += batchloss\n",
        "        epoch_acc += t_acc\n",
        "        count = i\n",
        "        \n",
        "        if i % 500 == 499:\n",
        "\n",
        "          print(\"epoch \", epoch + 1,\" \", i + 1,\"th batch\", \"accuracy: \", t_acc, \"loss: \", batchloss)\n",
        "          \n",
        "\n",
        "\n",
        "      train_pred = stack(train_pred)\n",
        "      train_truth = stack(train_truth)\n",
        "      print(\"epoch average auc: \", roc_auc_score(train_truth, train_pred))\n",
        "      print(\"epoch average loss: \", epoch_loss/(len(train_patient)))\n",
        "\n",
        "      train_roc_auc.append(roc_auc_score(train_truth, train_pred))\n",
        "\n",
        "      train_loss.append(epoch_loss/(len(train_patient)))\n",
        "  \n",
        "      LSTM.eval()\n",
        "      \n",
        "      val_epoch_loss = 0.0\n",
        "      val_epoch_acc = 0.0  \n",
        "      with torch.no_grad():\n",
        "        for j, dat in enumerate(dataloadingforval, 0):\n",
        "\n",
        "          v_image_in, v_label_in, v_meta = dat\n",
        "          \n",
        "          \n",
        "\n",
        "\n",
        "          v_label_in= v_label_in.to(device)\n",
        "\n",
        "          v_meta= v_meta.to(device)\n",
        "\n",
        "          v_meta =v_meta.view(pic,-1,19)\n",
        "          \n",
        "  \n",
        "          pred, out = model1(v_image_in, v_meta)\n",
        "          pred2 = model2(v_image_in)  \n",
        "          pred[pred<thres] =0\n",
        "          pred[pred>=thres] =1\n",
        "\n",
        "          pred2[pred2<thres2] =0\n",
        "          pred2[pred2>=thres2] =1\n",
        "          pred = torch.cat((pred,pred2),dim=-1)\n",
        "\n",
        "          val_output = torch.cat((out,pred), dim =-1)\n",
        "          val_output = LSTM(val_output.float())\n",
        "\n",
        "      \n",
        "          v_label_in=v_label_in.view(-1, 1).type_as(val_output)\n",
        "                \n",
        "\n",
        "          loss = criterion(val_output, v_label_in)\n",
        "\n",
        "          v_prediction = torch.sigmoid(val_output)\n",
        "          \n",
        "\n",
        "          \n",
        "          batchloss = loss.item()\n",
        "\n",
        "\n",
        "          final_prediction.append(v_prediction.detach().cpu().numpy())\n",
        "\n",
        "          ground_truth.append(v_label_in.cpu().numpy())\n",
        "\n",
        "        \n",
        "\n",
        "          if j % 100 == 99:\n",
        "\n",
        "\n",
        "            print(\"this is \", j+1, \"th patch\")\n",
        "\n",
        "\n",
        "          val_epoch_loss += batchloss\n",
        "    \n",
        "\n",
        "        final_prediction = stack(final_prediction)\n",
        "\n",
        "        ground_truth = stack(ground_truth)\n",
        "      \n",
        "\n",
        "\n",
        "        print(\"epoch average loss for validation: \", val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "\n",
        "      print(\"roc_auc_score\", roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "      val_roc_auc.append(roc_auc_score(ground_truth, final_prediction))\n",
        "\n",
        "      val_loss.append(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "\n",
        "      scheduler.step(val_epoch_loss/(len(val_patient)))\n",
        "\n",
        "  temp_list = pd.DataFrame({'train_roc_auc' : train_roc_auc,\n",
        "                                  'train_loss' : train_loss,\n",
        "                                  'val_roc_auc' : val_roc_auc,\n",
        "                                  'val_loss' : val_loss,\n",
        "                                  }, \n",
        "                                  columns=['train_roc_auc','train_loss', 'val_roc_auc','val_loss' ])\n",
        "\n",
        "  temp_list.to_csv(\"/content/Double_CNN_LSTM_with_Attention_with_metainfo_folderNo._{}.csv\".format(time), index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Paper_Code_Submission.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}